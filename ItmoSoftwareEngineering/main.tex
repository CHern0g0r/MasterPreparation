%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}
% \documentclass[14pt]{extarticle}
\usepackage{pdfpages}

\input{structure.tex} % Include the file specifying the document structure and custom commands

%----------------------------------------------------------------------------------------
%	ASSIGNMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Software Engineering} % Title of the assignment

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title

\section{Математика и алгоритмы}

\subsection{Системы линейных алгебраических уравнений. Теорема Кронекера-
Капелли. Общее решение системы алгебраических уравнений.}

\D{
    СЛАУ = система уровнений, каждое из которых линейно. Коэффициенты
    в уравнениях, а также переменные принимают значения в каком-либо поле.
}

СЛАУ можно представить в матричном виде: $Ax = b,\ A \in F^{m\times n}, b \in F^m$

Две системы эквивалентны, если множество их решений совпадает.

Эквивалентные преобразования:
\begin{itemize}
    \item Умножение на коэффициент
    \item Сложение с другим уравнением
\end{itemize}

$C$ - невырожденная матрица (полный ранг, det != 0)
$\Rightarrow Ax = b \sim CA x = C b$

$\Rightarrow \exists A^{-1} \rightarrow x = A^{-1} b$

\T[Кронекера-Капелли]{
    Система совместна $\iff rk A = rk (A | b)$
}

Методы решения:
\begin{itemize}
    \item Гаусса (Приведение к треугольному виду)
    \item Кронекера (Заменяем по очереди каждый столбец на $b$,
    считаем определитель $\Delta_i$, $x_i = \frac{\Delta_i}{\Delta}$)
    \item Обратной матрицей
    \item 
\end{itemize}


\subsection{Матрицы. Ранг матрицы, ранг произведения матриц, ранг 
транспонированной матрицы. Определитель матрицы. Определитель
произведения.}

\href{https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0_(%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0)}{Матрицы}

Ранг матрицы = количество линейно независимых столбцов (строк).

$rk A = rk A^T$

$rk AB \leq min(rk A, rk B)$ (Столбец $AB$ представляется как линейная
комбинация столбцов $A (B)$)

\href{https://ru.wikipedia.org/wiki/%D0%9E%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C}{Определитель матрицы}

$det(AB) = det A \cdot det B$


\subsection{Основная теорема арифметики. Малая теорема Ферма, функция
Эйлера. Мультипликативность функции Эйлера. Теорема Эйлера.}

\href{https://ru.wikipedia.org/wiki/%D0%9E%D1%81%D0%BD%D0%BE%D0%B2%D0%BD%D0%B0%D1%8F_%D1%82%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%B0%D1%80%D0%B8%D1%84%D0%BC%D0%B5%D1%82%D0%B8%D0%BA%D0%B8}{Основная теорема арифметики}

\T[Малая теорема ферма]{
    $p$ - простое, $a$ - целое $a \nmid p \Rightarrow a^{p-1}\equiv 1 (mod\ p)$
}

\href{https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D0%BB%D0%B0%D1%8F_%D1%82%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%A4%D0%B5%D1%80%D0%BC%D0%B0}{мтф}

\D{
    Функция Эйлера = $\phi(n) = |\{x\in \mathbb{N}: x < n \wedge gcd(x, n) = 1\}|$

    $\forall n, m :\ gcd(n, m) = 1 \rightarrow \phi(nm) = \phi(n) \cdot \phi(m)$
}
\href{https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%AD%D0%B9%D0%BB%D0%B5%D1%80%D0%B0}{ссыль}

\T[Теорема Эйлера]{
    $gcd(a, m) = 1 \Rightarrow a^{\phi(m)} \equiv 1 (mod\ m)$
}

\href{https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%AD%D0%B9%D0%BB%D0%B5%D1%80%D0%B0_(%D1%82%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D1%87%D0%B8%D1%81%D0%B5%D0%BB)}{ТЭ}


\subsection{Вероятностное пространство. Независимые события. Теорема
сложения. Условная вероятность. Полная система событий. Формула
полной вероятности. Формула Байеса.}

\D{
    Вероятностное пространство = $(\Omega, \m{A}, \mathbb{P})$
    \begin{itemize}
        \item $\Omega$ = произвольное непустое множество элементарных событий
        \item $\m{A}$ = $\sigma$-алгебра (замкнуто по дополнениям + объединение счетного) подмножеств $\Omega$, называемых случайными событиями
        \item $\mathbb{P}$ = вероятностная мера ($\sigma$-аддитивная мера), т.ч. $\mathbb{P}(\Omega) = 1$
    \end{itemize}
}

\href{https://ru.wikipedia.org/wiki/%D0%92%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%BD%D0%BE%D0%B5_%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D1%81%D1%82%D0%B2%D0%BE}{Вероятностное пространство}

\D{
    События $A, B$ независимы $\iff P(AB) = P(A) \cdot P(B)$
}
\href{https://ru.wikipedia.org/wiki/%D0%9D%D0%B5%D0%B7%D0%B0%D0%B2%D0%B8%D1%81%D0%B8%D0%BC%D0%BE%D1%81%D1%82%D1%8C_(%D1%82%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%B2%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%B5%D0%B9)}{Независимые события}

\D{
    Условная вероятность: $P(B) > 0 \Rightarrow P(A|B) = \frac{P(AB)}{P(B)}$
}

\D{
    Полная система событий = система случайных событий такая, что в результате произведённого случайного эксперимента непременно произойдет одно и только одно из них.
}

\D{
    Формула полной вероятности:

    $P(B_i) > 0 \wedge B_i \cap B_j = \emptyset \wedge \bigcup B_i = \Omega \Rightarrow
    P(A) = \sum P(A | B_i) P(B_i)$
}

\D{
    Формула Байеса:

    $P(A | B) = \frac{P(B | A) P(A)}{P(B)}$
}


\subsection{Случайная величина и её функция распределения. Совместное
распределение случайных величин. Распределение суммы независимых случайных величин.}

\href{https://ru.wikipedia.org/wiki/%D0%A1%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D0%B0%D1%8F_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D0%B0}{Случайная величина}

\D{
    Функция распределения случайной величины $\xi$:

    $F_\xi(x) = \mathbb{P}(\xi \leq x)$
}

\href{https://mipt.ru/education/chair/mathematics/study/methods/%D0%A1%D0%A0%D0%A1%D0%92_%D0%A1%D0%B0%D0%BC%D0%BE%D1%80%D0%BE%D0%B2%D0%B0(2).pdf}{Совместное распределение, сумма независимых}


\subsection{Математическое ожидание и дисперсия случайной величины, их
свойства.}

$E[X] = \int\limits_{\Omega} \xi(\omega) d \mathbb{P}(d \omega) =
\int\limits_{-\infty}^\infty x d F_\xi(x)$

\href{https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BE%D0%B6%D0%B8%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5}{Матожидание}

Свойства:
\begin{itemize}
    \item $E[a] = a$
    \item $E[a X + b Y] = a E[X] + b E[Y]$
    \item $0 \leq X \leq Y$ п.в. $\wedge E[Y] < \infty \Rightarrow 0 \leq E[X] \leq E[Y]$
    \item $X = Y$ п.в. $\Rightarrow E[X] = E[Y]$
    \item $X, Y$ - нез $\Rightarrow E[XY] = E[X] E[Y]$
\end{itemize}

$D[X] = E(X - E(X))^2$

\href{https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D1%81%D0%BF%D0%B5%D1%80%D1%81%D0%B8%D1%8F_%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D0%BE%D0%B9_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D1%8B}{Дисперсия}

Свойства:
\begin{itemize}
    \item $D[X] \geq 0$
    \item $D[X] < \infty \Rightarrow E[X] < \infty$
    \item $D[X] = 0 \iff X = E[X]$ п.в.
    \item $D[X + Y] = D[X] + D[Y] + cov(X, Y)$
    \item $D[\sum c_i X_i] = \sum c_i^2 D[X_i] + 2 \sum c_i c_j cov(X_i, X_j)$
    \item $D[a X] = a^2 D[X]$
    \item $D[-X] = D[X]$
    \item $D[X + b] = D[X]$
    \item 
\end{itemize}


\subsection{Теорема Больцано-Вейерштрасса и критерий Коши для числовой
последовательности.}

\T[Больцано-Вейерштрасса]{
    $\{x_i\} \subset R^n$ - последовательность, $\forall k ||x_k|| \leq C \in R_+$

    $\Rightarrow$

    $\exists \{k_i\}: \{x_{k_i}\}$ сходится к некоторой точке пространства $R^n$

}

\href{https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%91%D0%BE%D0%BB%D1%8C%D1%86%D0%B0%D0%BD%D0%BE_%E2%80%94_%D0%92%D0%B5%D0%B9%D0%B5%D1%80%D1%88%D1%82%D1%80%D0%B0%D1%81%D1%81%D0%B0}{Т. Больцано-Вейерштрасса}

\T[Критерий Коши]{
    $\{a_n\} \subset R^n$

    $\exists lim a_n \iff \forall \varepsilon > 0 \exists N: \forall m, n > N: |a_m - a_n| < \varepsilon$
}

\href{https://ru.wikipedia.org/wiki/%D0%9A%D1%80%D0%B8%D1%82%D0%B5%D1%80%D0%B8%D0%B9_%D0%9A%D0%BE%D1%88%D0%B8}{Критерий Коши}


\subsection{Два определения предела функции одной и нескольких переменных:
с помощью окрестностей и через пределы последовательностей.}

По Гейне:
$A = \lim\limits_{x \to x_0} f(x) \iff
\forall \{x_n\}: (\lim x_n = x_0 \wedge x_0 \notin \{x_n\})
\rightarrow (\lim f(x_n) = A)$

По Коши:
$\lim\limits_{x \to x_0} f(x) = A \iff
\forall \varepsilon > 0 \exists \delta = \delta(\varepsilon) > 0:
\forall x : (0 < |x - x_0| < \delta) \rightarrow (|f(x) - A| < \varepsilon)$



\section{Программирование}
\subsection{Архитектура компьютера: архитектура фон Неймана, гарвардская
архитектура}

\D {Архитектура Фон Неймана -- принцип, когда команды и данные хранятся в памяти компьютера (обычно в одной памяти). }

Овновные принципы:
\begin{itemize}
    \item Принцип однородности памяти
    
    Команды и данные хранятся в одной и той же памяти и внешне в памяти неразличимы. Распознать их можно только по способу использования; то есть одно и то же значение в ячейке памяти может использоваться и как данные, и как команда, и как адрес в зависимости лишь от способа обращения к нему. Это позволяет производить над командами те же операции, что и над числами, и, соответственно, открывает ряд возможностей. Так, циклически изменяя адресную часть команды, можно обеспечить обращение к последовательным элементам массива данных. Такой приём носит название модификации команд и с позиций современного программирования не приветствуется. Более полезным является другое следствие принципа однородности, когда команды одной программы могут быть получены как результат исполнения другой программы. Эта возможность лежит в основе трансляции — перевода текста программы с языка высокого уровня на язык конкретной вычислительной машины.
    
    \item Принцип адресности
    
    Структурно основная память состоит из пронумерованных ячеек, причём процессору в произвольный момент доступна любая ячейка. Двоичные коды команд и данных разделяются на единицы информации, называемые словами, и хранятся в ячейках памяти, а для доступа к ним используются номера соответствующих ячеек — адреса.
    
    \item Принцип программного управления
    
    Все вычисления, предусмотренные алгоритмом решения задачи, должны быть представлены в виде программы, состоящей из последовательности управляющих слов — команд. Каждая команда предписывает некоторую операцию из набора операций, реализуемых вычислительной машиной. Команды программы хранятся в последовательных ячейках памяти вычислительной машины и выполняются в естественной последовательности, то есть в порядке их положения в программе. При необходимости, с помощью специальных команд, эта последовательность может быть изменена. Решение об изменении порядка выполнения команд программы принимается либо на основании анализа результатов предшествующих вычислений, либо безусловно.
\end{itemize}

Узкое место данной архитектуры -- шина данных. Совместное использование шины для памяти программ и памяти данных приводит к узкому месту архитектуры фон Неймана, а именно ограничению пропускной способности между процессором и памятью по сравнению с объёмом памяти. Из-за того, что память программ и память данных не могут быть доступны в одно и то же время, пропускная способность канала «процессор-память» и скорость работы памяти существенно ограничивают скорость работы процессора — гораздо сильнее, чем если бы программы и данные хранились в разных местах.

Данная проблема решается совершенствованием систем кэширования, что в свою очередь усложняет архитектуру систем и увеличивает риск возникновения побочных ошибок (например, проблема когерентности памяти).

\D{Гарвардская архитектура -- архитектура, основными признаками которой являются:

хранилище инструкций и хранилище данных представляют собой разные физические устройства

канал инструкций и канал данных также физически разделены}

В данной архитектуре есть возможность одновременно загружать инструкции и данные, что ускоряет выполнение. (В отличие от арх. Фон Неймана, где может загружаться только что-то одно)

В гарвардской архитектуре характеристики устройств памяти для инструкций и памяти для данных не обязательно должны быть одинаковыми. В частности, ширина слова, тактирование, технология реализации и структура адресов памяти могут различаться. В некоторых системах инструкции могут храниться в памяти только для чтения, в то время как для сохранения данных обычно требуется память с возможностью чтения и записи. В некоторых системах требуется значительно больше памяти для инструкций, чем памяти для данных, поскольку данные обычно могут подгружаться с внешней или более медленной памяти. Такая потребность увеличивает битность (ширину) шины адреса памяти инструкций по сравнению с шиной адреса памяти данных.

\subsection{Компиляция программ. Как устроен компилятор? Зачем нужен
компилятор. Интерпретация программ}

\D {Компилятор -- по сути черный ящик, который из исходного кода программы делает исполняемый файл, либо какой-то байт-код, который потом можно передать в виртуальную машину.}

Состоит обычно из нескольких частей

\begin{itemize}
    \item Лексический анализатор или сканер
    \item Синтаксический анализатор или парсер
    \item Семантический анализатор
    \item один или несколько генераторов кода и один или несколько оптимизаторов
    \item Также часто относят сборщик и компоновщик
\end{itemize}

Лексический анализатор(сканер) -- последовательно считывает все слова (токены) в тексте программы, преобразуя их в конструкции, которые затем используются для дальнейшего разбора текста.

Следом за лексическим анализом может быть препроцессор. Тем, кто знаком с языками программирования C или С++, нет нужды объяснять, в чём состоит его функция. Для остальных же скажу, что основная задача препроцессора - это замена одних лексем другими, которые были заранее определены в тексте программы. Используется препроцессор также для условной компиляции (т.е. когда кусок кода должен быть откомпилирован только при выполнении определённых условий - для определённой платформы, только при отладочном билде и т.д. и т.п.), для выполнения определённых макросов (как в том же C/C++) и некоторых других подобных вещей. Препроцессор не является обязательной частью компилятора, поскольку многие языки программирования не нуждаются в нём.

Следующий этап - это синтаксический анализ, или парсинг. Этот этап компиляции выполняется синтаксическим анализатором, или парсером, и является, пожалуй, самым важным и, если можно так сказать, ответственным этапом компиляции. Компилятор рассматривает все токены, и, в зависимости от их значения и положения в тексте программы, формирует так называемое дерево разбора. То есть программа, бывшая до этого в недрах компилятора просто линейным набором символов, становится деревом, элементы которого расположены в соответствии с грамматикой того языка программирования, для которого написан данный конкретный компилятор.

Следом за синтаксическим анализом следует этап анализа семантического. Если синтаксический анализатор строил скелет нашей программы, то семантический помогает этому скелету обрасти плотью. Программа наполняется смыслом: переменные становятся переменными, объекты - объектами, а баги - багами. На самом деле, никакого волшебства не происходит - просто дерево разбора, терпеливо построенное парсером, дополняется семантической информацией о значении идентификаторов. Кстати, на этом этапе возникают и многие ошибки компиляции - например, такие, как несоответствие типов. Хотя, конечно, на парсинг тоже приходится изрядное количество ошибок, без которых, к сожалению, текст свеженаписанной программы обходится крайне редко даже у очень опытных программистов.

Дальше пути различных компиляторов расходятся. В большинстве компиляторов следом за этапом семантического анализа идёт перевод программы в некоторый промежуточный код, который может использоваться для генерации кода под разные аппаратные платформы. Если компилятор выполняет компиляцию только для какой-то одной аппаратной платформы, то программа может транслироваться в коды на языке Ассемблера соответствующей процессорной архитектуры, или, если компилятор трудится для какой-то виртуальной машины (как, например, в случае Java или Microsoft .NET), то переводиться программа может затем в специальный байт-код, понятный соответствующей виртуальной машине. Тем не менее, в большинстве современных компиляторов нет непосредственной трансляции в ассемблерный код - даже если в итоге компилятор не должен стараться для создания кросс-платформенных программ, всё равно, сначала идёт трансляция программы в какой-то промежуточный код, а только потом уже в исполняемый. Причина этого в оптимизации кода.

Современные компиляторы, даже самые слабенькие и плохонькие, поддерживают хотя бы базовую оптимизацию кода. Более мощные коммерческие компиляторы содержат в себе очень мощные алгоритмы оптимизации кода, которые позволяют при некоторых условиях сделать её в разы быстрее. Особенно мощными в плане оптимизации давным-давно тому назад считались компиляторы производства Watcom, сейчас, вроде бы, постепенно восстанавливающие свою былую славу в виде open-source продукта. Потом пальма первенства перешла к компиляторам Intel, и сейчас именно они считаются самыми лучшими компиляторами в плане оптимизации. Что ж, это довольно логично - кому, как ни создателям процессоров, знать, как лучше всего оптимизировать программы для работы на них. Впрочем, не важно, плоха оптимизация в компиляторе или нет - главное, что в любом оптимизирующем компиляторе есть модуль, называемый оптимизатором, который начинает свою работу после генератора промежуточного кода. Справедливости ради стоит сказать, что оптимизатор может работать и после генерации уже исполняемого кода, но в наши дни такая схема встречается уже редко, поскольку производители компиляторов, как правило, выпускают целую линейку подобных продуктов для разных языков программирования и стараются делать оптимизаторы, которые можно встроить в любой из этих компиляторов. Какими именно методами оптимизатор может повышать скорость работы программы - это тема отдельной статьи, которую, возможно, вы когда-нибудь и сможете увидеть на страницах "Компьютерных вестей".

В любом случае, работа компилятора заканчивается генерацией исполняемого кода. Это может быть код виртуальной машины или код на языке ассемблера, но этот код уже пригоден для выполнения скомпилированной программы.

Как правило, компиляторы снабжаются, как я уже говорил выше, сборщиком и компоновщиком (ассемблером и линкером, как их называют чаще). Они помогают компилятору создать из исходного текста программы не просто ассемблерный код, а исполняемый файл, который программист может передать пользователю той операционной системы, для которой он писал программу, а тот уже сможет его запустить точно таким же образом, каким привык запускать все другие программы на своём компьютере.

Ассемблер и компоновщик в ряде случаев встроены прямо в компилятор, в других же случаях они выделяются в отдельные программы, которые запускаются после завершения работы самого компилятора. Их может и вовсе не быть, как, например, для компиляторов, преобразующих программы с одного языка высокого уровня на другой высокоуровневый язык (так называемых фронт-эндов), или они могут присутствовать только в виде, например, специфического сборщика, создающего код для виртуальной машины и помещающего его в какую-то специальную оболочку компоновщика (классический пример - Java с её JAR-файлами). Стоит, тем не менее, сказать пару слов о назначении этих двух инструментов.

Ассемблер (сборщик) - это программа, которая переводит код на языке Ассемблера в инструкции (операционные коды) процессора или в инструкции виртуальной машины. Поскольку язык Ассемблера - это низкоуровневый язык, то ассемблер не считают компилятором, хотя, конечно, он тоже производит некоторые этапы разбора программы, характерные для компилятора.

Компоновщик создаёт из того кода, который сгенерировал ассемблер, исполняемые файлы. Даже для одной и той же процессорной архитектуры исполняемые файлы будут отличаться в зависимости от операционной системы. Например, для Windows формат исполняемых файлов - это Portable Executable (PE), а для Linux - Executable Linked File (EXE).

\D {Интерпретация программ -- построчный анализ, обработка и выполнение исходного кода программы или запроса (в отличии от компиляции, где анализируется весь код перед запуском без выполнения)}

Простой интерпретатор -- анализирует и тут же выполняет программу покомандно или построчно, по мере поступления ее исходного кода на вход. Достоинство -- мнгновенная реакция, недостаток -- ошибки отлавливаются только во время исполнения.

Интерпретатор компилирующего типа -- Сначала переводим код программы в промежуточное представление, например байт код, а затем скармливаем выполнятору

Достоинством таких систем является большее быстродействие выполнения программ за счёт выноса анализа исходного кода в отдельный, разовый проход, и минимизации этого анализа в интерпретаторе. Недостатки — большее требование к ресурсам и требование на корректность исходного кода. Применяется в таких языках, как Java, PHP, Tcl, Perl, REXX (сохраняется результат парсинга исходного кода[8]), а также в различных СУБД.

В случае разделения интерпретатора компилирующего типа на компоненты получаются компилятор языка и простой интерпретатор с минимизированным анализом исходного кода. Причём исходный код для такого интерпретатора не обязательно должен иметь текстовый формат или быть байт-кодом, который понимает только данный интерпретатор, это может быть машинный код какой-то существующей аппаратной платформы. К примеру, виртуальные машины вроде QEMU, Bochs, VMware включают в себя интерпретаторы машинного кода процессоров семейства x86.

Некоторые интерпретаторы (например, для языков Лисп, Scheme, Python, Бейсик и других) могут работать в режиме диалога или так называемого цикла чтения-вычисления-печати (англ. read-eval-print loop, REPL). В таком режиме интерпретатор считывает законченную конструкцию языка (например, s-expression в языке Лисп), выполняет её, печатает результаты, после чего переходит к ожиданию ввода пользователем следующей конструкции.

\subsection{Языки программирования высокого уровня. Переменные, массивы, условия, циклы. Функции. Рекурсия.  Как это реализовывается в машинном коде.}

Есть переменные, можно объявлять, можно изменять значение, можно присваивать одной значение другой.

Много разных типов, обычно это bool, char, short, int, long, string, double, float (еще есть void, это типа сырые данные, еще есть указатели всякие, они всегда одного размера, просто говорят где в памяти лежит объект)

Массив -- Большой кусок памяти подряд, выделенный для переменных одного типа. Можно обращаться к любому элементу с помощью смещения относительно начала.

Есть понятие условного оператора -- проверяем условие, если оно выполнено идем внутрь. Еще можно добавить альтернативные ветки (как с еще одним условием, так и без него, тогда туда попадет в случае если не выполнились предыдущие)

Есть switch который сравнивает значение с набором констант. С помощью break можно прекратить рассмотрение дальше.

Еще есть понятие цикла -- пишем по чему итерируемся, условие, по которому итерируемся, и изменение после очередной итерации

\D {Функция -- именованная часть программы, которая может вызваться из другой части программы}

Задаем возвращаемое значение, название, параметры которые использует. Внутри пишем логику, и можем сделать return. При вызове функции сверяются типы, как если бы переменная этого типа инициализировалась. Также можно одинаково называть функции с разными сигнатурами, тогда по количеству параметров компилятор поймет какую надо вызвать. Это называется перегрузкой

Рекурсия -- вызов функции из самой себя.

Вообще, при вызове функции на стек кладутся переменные, которые в нее передались и код возврата, при выхода это все добро снимается. При рекурсии получается много кадров, поэтому сильно глубоко лезть не круто.

Про машинный код есть что-то такое но я не смог в этом разобраться \href{https://otus.ru/nest/post/1581/}{https://otus.ru/nest/post/1581/}

\subsection{Объектно-ориентированное программирование. Основные принципы}

{\bf Основные принципы ООП}

Объектно-ориентированное программирование основано на «трех китах» - трех важнейших принципах, придающих объектам новые свойства. Этими принципами являются инкапсуляция, наследование и полиморфизм.

{\bf Инкапсуляция}

Инкапсуляция есть объединение в единое целое данных и алгоритмов обработки этих данных. В рамках ООП данные называются полями объекта, а алгоритмы - объектными методами.

Инкапсуляция позволяет в максимальной степени изолировать объект от внешнего окружения. Она существенно повышает надежность разрабатываемых программ, т.к. локализованные в объекте алгоритмы обмениваются с программой сравнительно небольшими объемами данных, причем количество и тип этих данных обычно тщательно контролируются. В результате замена или модификация алгоритмов и данных, инкапсулированных в объект, как правило, не влечет за собой плохо прослеживаемых последствий для программы в целом (в целях повышения защищенности программ в ООП почти не используются глобальные переменные).

Другим немаловажным следствием инкапсуляции является легкость обмена объектами, переноса их из одной программы в другую. Можно сказать, что ООП «провоцирует» разработку библиотек объектов, таких как Turbo Vision.

{ \bf Наследование}

Наследование есть свойство объектов порождать своих потомков. Объект-потомок автоматически наследует от родителя все поля и методы, может дополнять объекты новыми полями и заменять (перекрывать) методы родителя или дополнять их.

Принцип наследования решает проблему модификации свойств объекта и придает ООП в целом исключительную гибкость. При работе с объектами программист обычно подбирает объект, наиболее близкий по своим свойствам для решения конкретной задачи, и создает одного или нескольких потомков от него, которые «умеют» делать то, что не реализовано в родителе.

Последовательное проведение в жизнь принципа «наследуй и изменяй» хорошо согласуется с поэтапным подходом к разработке крупных программных проектов и во многом стимулирует такой подход.

{ \bf Полиморфизм}

Полиморфизм - это свойство родственных объектов (т.е. объектов, имеющих одного общего родителя) решать схожие по смыслу проблемы разными способами. В рамках ООП поведенческие свойства объекта определяются набором входящих в него методов. Изменяя алгоритм того или иного метода в потомках объекта, программист может придавать этим потомкам отсутствующие у родителя специфические свойства. Для изменения метода необходимо перекрыть его в потомке, т.е. объявить в потомке одноименный метод и реализовать в нем нужные действия. В результате в объекте-родителе и объекте-потомке будут действовать два одноименных метода, имеющие разную алгоритмическую основу и, следовательно, придающие объектам разные свойства. Это и называется полиморфизмом объектов.

В Турбо Паскале полиморфизм достигается не только описанным выше механизмом наследования и перекрытия методов родителя, но и их виртуализацией (см. ниже), позволяющей родительским методам обращаться к методам потомков.

\subsection{Язык программирования: как происходит компиляция, интерпретация, выполнение.}

Тут будет про питон(CPython).

Написали прогу, хотим запустить

\begin{enumerate}
    \item Сначала читается код, проверяется на форматирование и синтаксис. При обнаружении ошибок говорит что что-то не так написано
    
    Также в этот момент происходит анализ аргументов командной строки, установка флагов программы, чтение переменных среды
    
    \item Компиляция. Интерпретатор переводит исходные инструкции в байт-код. Надо для повышения скорости. Если есть право записи -- сохранит в .pyc файл, и будет переиспользывать его, если исходный код не поменялся.
    
    \item Выполнение. Скомпилированный код отправляем на виртуальную питон машину. Здесб выполняется байт-код. Выполняется построчно, если есть ошибка -- падаем с ней. По сути -- цикл с перебором и выполнением инструкций
\end{enumerate}

Это вкратце, для плюсов наверное сначала компилируем компилятором, там всякие парсеры, потом линкуем, получаем машинный код который уже можно запускать.

\subsection{Язык программирования: основы синтаксиса, встроенные типы,
массивы и структуры, функции, работа с динамической памятью}
 
Ну если тут писать про питон, то все понятно.

Вложенность по отступам, точки с запятой не нужны, можно писать инструкции в несколько строк если они в скобках, или есть переносы по $\\\\$
 
 Базовые типы
 \begin{itemize}
     \item int
     \item str
     \item float
     \item bool
     \item None
 \end{itemize}
 
 Массивы объявляются через [] или list(), еще есть set(), dict() или {}, tuple. Надеюсь тут все более менее понятно, можно еще рассказать про отличия и за скока че работает, про list-comprehensions, про то что можем хэшировать только immutable штуки (строка в питоне тоже immutable, хотим менять ее -- храним как массив символов и делаем join)

Фунции объявлятся через 

def fun(params, x=1, *args, **kwargs):

~~~~blah-blah-blah

тут args это кортеж, в который засунется все неименованное что осталось

kwargs -- все именованное чего нет в сигнатуре функции.

Можно внутри функции, тогда можно вызвать только из функции родителя.

Есть модификатор global который дает доступ к переменным глобальным, а обычно перетираем область видимости.

еще есть лямбды -- анонимные функции

Все объекты выделяются и удаляются автоматически, следят за ними через счетчик ссылок, если он 0 то удаляем (если точнее, то помечаем память как свободную, что может вести к проблемам с фрагментацией, но это все не точно и личное суждение)

\subsection{Язык программирования: классы и ООП}

Тут хочу про плюсы, потому что ооп на питоне полная фигня

Есть классы, можно указывать поля и функции, есть модификаторы public, protected, private.

Еще есть static, дает пользоваться без объекта

Есть наследование от классов, наследование бывает public, protected и private, собственно все что отнаследовали урезаем по доступу до того, каким видом отнаследовали.

Также есть множественное наследование -- берем все. Проблема -- есть повторения, можно перегружать, можно обращаться к конкретному суперклассу. При наследовании вызываются конструкроры деструкторы в прямом и обратном порядке наследования. Если ромбовидное, то конструктор того класса, у которого 2 ребенка вызовется 2 раза, что плохо. Ждя таких случаев есть virtual наследование. Оно во-первых не вызывает лишних конструкторов, а во-вторых, если есть 2 одинаковых метода, которые одинаковые только потому что отнаследовались от одного класса и не переопределились, а потом мы наследуемся от этих 2 детей базового класса, то тогда не будет ошибки компиляции для самого нижнего, т.к. возьмется тот самый метод базового класса.

Есть понятие виртуальной функции -- это для абстрактных классов и интерфейсов, ее обязательно перегружать, может быть без реализации.

Полиморфизм -- понятно, можем понаделать разных классов и обращаться как к базовому, вызывая методы базового. При этом если перегрузили, то выщовутся перегруженные версии.


\end{document}
