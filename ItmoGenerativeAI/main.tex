%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}
% \documentclass[14pt]{extarticle}
\usepackage{pdfpages}
\usepackage{float}

\input{structure.tex} % Include the file specifying the document structure and custom commands

%----------------------------------------------------------------------------------------
%	ASSIGNMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Generative AI} % Title of the assignment

%----------------------------------------------------------------------------------------

\DeclareMathOperator*\uplim{\overline{lim}}


\begin{document}

\maketitle % Print the title
\section{Математика и анализ данных}

\subsection{Числовые ряды. Абсолютная и условная сходимость. Признаки сходимости числовых рядов.}

\subsubsection{Числовые ряды}

$\sum\limits_{k=1}^{\infty} a_{k} = a_{1} + a_{2} + a_{3} + \cdots$ -- числовой ряд

Сходимость ряда означает существование конечной суммы, т.е. $\sum\limits_{k=1}^{\infty} a_{k} = S$ где $S$ -- конечное число, иначе ряд считается расходящимся.

\subsubsection{Абсолютная и условная сходимость}

Ряд $\sum\limits_{k=1}^{\infty} a_{k}$ называется {\bf абсолютно} сходящимся, если сходится ряд из модулей $\sum\limits_{k=1}^{\infty} |a_{k}|$, иначе ряд называется {\bf условно} сходящимся

\subsubsection{Признаки сходимости числовых рядов} 

{\bf Знакоположительные ряды} (ряды с положительными членами):

Критерий сходимости знакоположительных рядов-- знакоположительный ряд $\sum\limits_{k=1}^{\infty} a_{k}$ сходится тогда и только тогда, когда последовательность его частичных сумм $S(n) = \sum\limits_{k=1}^{k=n}a_{k}$ ограничена сверху

{\bf Док-во:}

=>: ряд сходится, значит последовательность частичных сумм $\S(n) =\sum\limits_{k=1}^{n} a_{k}$ имеет предел равный $\sum\limits_{k=1}^{\infty} a_{k} = S$

<=: Пусть дан положительный ряд и последовательность частичных сумм ограничена сверху, заметим что последовательность частичных сумм неубывающая:
$$S_{n + 1} - S_{n} = a_{n + 1} \ge 0$$. Используя свойство из теоремы о монотонной последовательности получаем, что т.к. последовательность частичных сумм монотонно не убывает и ограничена сверху, значит она сходится и потому ряд сходится по определению.

{\bf Признак сравнения с мажорантой}

Пусть даны два положительных ряда $\sum\limits_{k=1}^{\infty} a_{k}$ и $\sum\limits_{k=1}^{\infty} b_{k}$. Если начиная с некоторого номера $n > N$ выполняется неравенство $0 \le a_n \le b_n$, то:

\begin{itemize}
	\item из сходимости рядя $\sum\limits_{k=1}^{\infty} b_{k}$ следует сходимость ряда $\sum\limits_{k=1}^{\infty} a_{k}$
	\item из расходимости ряда $\sum\limits_{k=1}^{\infty} a_{k}$ следует расходимость $\sum\limits_{k=1}^{\infty} b_{k}$
\end{itemize}

{\bf Док-во:}

Из неравенств на члены следует неравенство на частичные суммы $0 \le S_n \le \sigma_n$, дальше очев.


{\bf Признак Раабе}

Если для ряда $\sum\limits_{k=1}^{\infty} a_{k}$ существует предел $$R = \lim\limits_{n \rightarrow \infty} n (\frac{a_n}{a_{n+1}} - 1)$$, то при $R > 1$ ряд сходится, а при $R < 1$ -- расходится. Если $R = 1$, то жанный признак не говорит ничего.

{\bf Признак Гаусса}

Пусть для знакоположительного ряда $\sum\limits_{n=1}^{\infty} a_{n}$ отношение $\frac{a_n}{a_{n + 1}}$ может быть представлено в виде $$\frac{a_n}{a_{n + 1}} = \lambda + \frac{\mu}{n} + \frac{\theta_n}{n^2}$$, где $\lambda, \mu$ -- постоянные, а последовательность $\theta_n$ ограничена. Тогда 
\begin{itemize}
	\item ряд расходится если либо $\lambda > 1$, либо $\lambda = 1, \mu > 1$
	\item ряд расходится, если либо $\lambda < 1$, либо $\lambda = 1, \mu \le 1$
\end{itemize}


{\bf Знакопеременные ряды}

\D{Знакопеременными называются ряды, члены которых могут (стоять) быть как положительными, так и отрицательными.}


{\bf Признак Даламбера}

Слабее признака Коши, но зато проще

Если существует $\lim\limits_{n \rightarrow \infty}|\frac{a_{n + 1}}{a_n}| = r$, то 

\begin{itemize}
	\item если $r < 1$, то ряд абсолютно сходится
	\item если $r > 1$, то ряд расходится
	\item если $r = 1$, то данный признак ничего не говорит (сука)
\end{itemize}

{\bf Док-во:}

1. Пусть начиная с некоторого номера N верно неравенство $|\frac{a_{n+1}}{a_n}| \le q, 0 < q < 1$. Тогда перемножив члены начиная с N будем иметь что $\frac{a_{N+n}}{a_N} \le q^n$ откуда $|a_{N+n}| \le |a_{N}q^n|$, значит ряд $|a_{N+1}| + |a_{N+2}| + ...$ меньше бесконечной суммы убывающей геометрической прогрессии, поэтому он сходится

2. $|\frac{a_{n + 1}}{a_n}| \ge 1$ (с некоторого N), тогда можно записать $|a_{n+1}| \ge |a_n|$ значит модуль членов $a$ не стремится к 0 на бесконечности, значит последовательность не стремится к 0 а значит ряд не сходится.

3. Если просто меньше 1 до там хуйня какая-то мне впадлу
\\

{\bf Радикальный признак Коши} (ебаная оппозиция)

Если существует $\lim\lim\limits_{n \rightarrow \infty} \sqrt[n]{|a_n|} = r$, то

\begin{itemize}
	\item если $r < 1$ то ряд сходится абсолютно
	\item если $r > 1$ то ряд расходится
	\item если $r = 1$ то хз (опять??)
\end{itemize}

{\bf Док-во:} \href{https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B4%D0%B8%D0%BA%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA_%D0%9A%D0%BE%D1%88%D0%B8}{тут}
\\

{\bf Признак Лейбница}

Пусть для знакочередующегося ряда $$S = \sum\limits_{n=1}^{\infty}(-1)^{n-1}a_n, a_n \ge 0$$
выполняются следующие условия

\begin{itemize}
	\item С некоторого $N$ последовательность $a$ монотонно убывает, т.е. $a_{n+1} \le a_n$
	\item $\lim\limits_{n \rightarrow \infty}a_n = 0$
\end{itemize}

Тогда такой ряд сходится

{\bf Док-во:} \href{https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%9B%D0%B5%D0%B9%D0%B1%D0%BD%D0%B8%D1%86%D0%B0_%D0%BE_%D1%81%D1%85%D0%BE%D0%B4%D0%B8%D0%BC%D0%BE%D1%81%D1%82%D0%B8_%D0%B7%D0%BD%D0%B0%D0%BA%D0%BE%D1%87%D0%B5%D1%80%D0%B5%D0%B4%D1%83%D1%8E%D1%89%D0%B8%D1%85%D1%81%D1%8F_%D1%80%D1%8F%D0%B4%D0%BE%D0%B2}{здесь}\\
	
{\bf Признак Абеля}

\T {Числовой ряд $\sum\limits_{n=1}^{\infty}a_nb_n$ сходится, если выполнены следующие условия

\begin{itemize}
	\item Последовательность \{$a_n$\} монотонна и ограничена
	\item Ряд $\sum\limits_{n=1}^{\infty}b_n$ сходится
\end{itemize}
}
{\bf Proof:} \href{https://ib.mazurok.com/2015/06/16/%D0%BF%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA%D0%B8-%D0%B0%D0%B1%D0%B5%D0%BB%D1%8F-%D0%B8-%D0%B4%D0%B8%D1%80%D0%B8%D1%85%D0%BB%D0%B5/}{вот}\\
	
{\bf Признак Дирихле}

\T{Пусть выполнены условия:
\begin{itemize}
	\item последовательность частичных сумм $B_n = \sum\limits_{k=1}^{n}$ ограничена
	\item последовательность $a_n$, начиная с некоторого номера, монотонно убывает $a_n \ge a_{n+1}$
	\item $\lim\limits_{n\rightarrow\infty}a_n = 0$
\end{itemize}
Тогда ряд $\sum\limits_{n=1}^{\infty}a_nb_b$ сходится
}
	
{\bf Proof:} \href{https://ib.mazurok.com/2015/06/16/%D0%BF%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA%D0%B8-%D0%B0%D0%B1%D0%B5%D0%BB%D1%8F-%D0%B8-%D0%B4%D0%B8%D1%80%D0%B8%D1%85%D0%BB%D0%B5/}{вот}\\

\subsection{Кратные, поверхностные и криволинейные интегралы. Формулы Грина, Стокса и Остроградского}


\subsubsection{Интеграль4ики}
\D{Пусть дана $f(x)$ -- функция действительной переменной. {\bf Неопределенным интегралом} функции $f(x)$, или ее первообразной, называется такая функция $F(x)$, производная которой равна $f(x)$, т.е. $F^{'}(x) = f(x)$. Обозначается $F(x) = \int f(x)dx$ }


\D{Кратным интегралом называют множество интегралов, взятых от $d > 1$, например  $$\underbrace{\int...\int f(x_1,...,x_d)dx_{1}...dx_{d}}_{d}$$}

Замечание -- кратный интеграл -- определенный интеграл, при его вычислении всегда получается число

\D{Криволинейный интеграл -- интеграл вычисляемый вдоль какой-либо прямой.

Пусть $l$ -- пгладкая, без особых точек и пересечений кривая (может быть замкнутой), заданая параметрически $l: r(t)$, где $r$ -- радиус вектор, конец которого описывает кривую, а параметр $t$ направлен от начального значения $a$ к конечному значению $b$. Для интеграла второго рода направление, в котором движется параметр, определяет направление кривой $l$.

Также есть скалярная или векторная функция , которая рассматривается вдоль кривой $l: f(r)$

Еще есть разбиение отрезка параметризации, и разбиение кривой. Они соответствуют друг-другу (параметризация от параметра по факту сопостовляет точке из отрезка параметризации $[a, b]$ точку на прямой, и по разбиению параметризации разбивается кривая по соответствующим точкам, подробнее можно почитать на вики ссылку вставить не получилось:( )

Интегральная сумма для интеграла {\bf первого рода} -- сумма вида $\sum\limits_{k=1}^{n} f(r(\xi_i))\cdot|l_k|$ где $|l_k|$ -- длина соответствующего отрезка, $\xi_i$ -- точка на соответствующем отрезке

Интегральная сумма для интеграла {\bf первого рода} -- сумма вида $\sum\limits_{k=1}^{n} f(r(\xi_i))\cdot(r(t_k) = r(t_{k - 1})))$

Собственно, криволинейный интеграл это интегральная сумма с $n$ устремленным в бесконечность
}

Похоже на обычный определенный интеграл, только тут мы вместо оси выравниваемся на кривую какую-то, и по факту считаем площидь криволинейного цилиндра между кривой в пространстве и ее проекцией (вроде бы, но это не точно)


\D{Пусть $\Phi$ -- гладкая, ограниченная полная поверхность. Пусть далее на $\Phi$ задана функция $f(M) = f(x, y, z)$. Рассмотрим разбиение $T$ этой поверхности на часть $\Phi_i (i=1, ..., n)$ кусочно-гладкими кривыми и на каждой такой части выберем произвольную точку $M_i(x_i, y_i, z_i)$. Вычислив значение функции в этой точке $f(M_i) = f(x_i, y_i, z_i)$ и, приняв за $\sigma_i$ площадь поверхность $\Phi_i$, рассмотрим сумму $$I\{\Phi_i, M_i\} = \sum_i f(M_i)\sigma_i$$. Тогда число I называется пределом сумм $i\{\Phi_i, M_i\}$ если $$\forall \epsilon > 0 \exists \delta > 0 \forall T: d(T) < \delta \forall \{M_i\} |I\{\Phi_i, M_i\} - I| < \epsilon$$
Предел $I$ сумм $I\{\Phi_i, M_i\}$ при $d(T) \rightarrow 0$
 называется {\bf поверхностным интегралом первого рода} от функции $f(M)$ по поверхности $\Phi$ и обозначается $$I = \iint\limits_{\Phi} f(M)d\sigma$$} 

По сути -- берем поверхность в пространстве, а дальше как в криволинейном -- вместо отрезков оже куски пространства и т.д. получается магия какая-то.

\subsubsection{Формула Грина}

\D{Пусть $C$ -- положительно ориентированная кусочно-гладкая замкнутая кривая на плоскости, а $D$ -- область, ограниченная кривой $C$. Если фунеции $P = P(x, y)$, $Q = Q(x, y)$ определены в области $D$ и имеют неприрывные частные производные $\frac{\partial P}{\partial y}, \frac{\partial Q}{\partial x}$, то $$\oint Pdx + Qdy = \iint\limits_{D}(\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y})dxdy$$}
{\bf Док-во и еще:} \href{https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%93%D1%80%D0%B8%D0%BD%D0%B0}{here}
	
\subsubsection{Формула Стокса}

\D{Пусть на ориентируемом многообразии $M$ размерности $n$ заданы положительно ориентированное ограниченное $p-$мерное подмногообразие $\sigma (1 \le p \le n)$ и дифференциальная форма $\omega$ степени $p - 1$ класса $C^1$. Тогда если граница подмногообразия $\partial \sigma$ положительно ориентированаб то $$\int\limits_{\sigma}d\omega = \int\limits_{\partial \sigma \omega}$$}

Грубо говоря взяли поверхность, и с помощью дифференциалов перешли к интегралу по границе поверхности, как-то так, но надо глубже разбираться потому что очень много определений которые надо помнить

\subsubsection{Формула Остроградского (Гаусс сосать)}

\D{Пусть теперь $\partial V$ -- кусочно-гладкая гипперповерхность $(p = n - 1)$, ограничивающая некоторую область $V$ в $n-$мерном пространстве. Тогда интеграл дивергенции (это оператор который отображает векторное поле на скалярное -- $div F = \lim\limits_{V \rightarrow 0} \frac{\Phi_F}{V}$, где $\Phi_F$ -- поток векторного поля $F$ через сферическую поверхность площадью $S$ ограничивающую объем $V$, хуита какая-то хочу объяснение на пальцах) поля по области равен потоку поля через границу области $\partial V$: $$\int\limits_{V} div F dV = \int\limits_{\partial V} F d \Sigma$$.
	
В трехмерном пространстве $(n = 3)$ с координатами $\{x, y, z\}$ эквивалентнно $$\int\limits_{\partial V} F d \Sigma = \int\limits_{V}(\frac{\partial P}{\partial x} + \frac{\partial Q}{\partial y} + \frac{\partial R}{\partial z}) dV$$, или $$\iiint\limits_{\partial V} Pdydz + Qdzdx + Rdxdy = \iint\limits_{V} (\frac{\partial P}{\partial x} + \frac{\partial Q}{\partial y} + \frac{\partial R}{\partial z})dxdydz$$ }


Понятно что тут взяли и применили стокса на какой-то случай, но чет пиздец ребята)))


\subsection{Функциональные ряды, свойства равномерно сходящихся функциональных рядов. Степенные ряды. Ряд Тейлора.}

\subsubsection{Функциональные ряды}

\D {Функциональный ряд -- ряд, каждым членом которого является функция $u_k(x)$

Обозначается $\sum\limits_{k=1}^{\infty} u_k(x)$}

Функциональная последовательность $u_k(x)$ сходится {\bf поточечно} к функции $u(x)$, если $\forall x \in E \exists \lim\limits_{k \rightarrow \infty} u_k(x) = u(x)$

{\bf Равномерная сходимость} -- существует функция $u(x): E \rightarrow \mathbb{C}$ такая, что 

$sup |u_k(x) - u(x)| \xrightarrow {k \rightarrow \infty} 0, x \in E$

Функциональный ряд называется сходящимся {\bf поточечно}, если последовательность $S_n(x) = \sum\limits_{k=1}^{n} u_k(n)$ сходится поточечно. Аналогично для равномерной сходимости.

{\bf Необходимое условие равноменой сходимости ряда}

$u_k(x) \rightrightarrows 0$ при $k \rightarrow \infty$

Или, что эквивалентно $\forall \epsilon > 0 \exists n_0(\epsilon) \in \mathbb{N} : \forall x \in X, \forall n > n_0 |u_n(x)| < \epsilon$, где $X$ -- область сходимости

{\bf Свойства}

\begin{enumerate}
	\item {\bf Теоремы о непрерывности}
	
	Последовательность непрерывных в точке функций сходится к функции, непрерывной в этой точке.
	
	Последовательность $u_k(x) \rightrightarrows u(x)$
	
	$\forall k:$ функция $u_k(x)$ непрерывна в точке $x_0$
	
	Тогда и $u(x)$ непрерывна в $x_0$
	
	Ряд непрерывных в точке функций сходится к функции, непрерывной в этой точке.
	
	Ряд $\sum\limits_{k=0}^{\infty}u_k(x) \rightrightarrows S(x)$
	
	$\forall k$: функция непрерывна в точкке $x_0$
	
	Тогда $S(x)$ непрерывна в  $x_0$
	
	\item {\bf Теоремы об интегрировании}
	
	Рассматриваются действительнозначные функции на отрезке действительной оси
	
	{\it Теорема о переходе к пределу под знаком интеграла}
	
	$\forall k:$ функция $u_k(x)$ непрерывна на отрезке $[a, b]$
	
	$u_k(x) \rightrightarrows u(x)$ на $[a, b]$
	
	Тогда числовая последовательность $\{\int\limits_{a}^{b} u_k(x) dx\}$ сходится к конечному пределу $\int\limits_a^b u(x) dx$
	
	{\it Теорема о почленном интегрировании}
	
	$\forall k:$ функция $u_k(x)$ непрерывна на отрезке $[a, b]$
	
	$\sum\limits_{k=1}^{\infty}u_k(x) \rightrightarrows S(x)$ на $[a, b]$
	
	Тогда числовой ряд $\sum\limits_{k=1}^{\infty}\int\limits_{a}^{b} u_k(x) dx$ сходится и равен $\int\limits_a^b S(x) dx$
	
	\item {\bf Теоремы о дифференцировании}
	
	Рассматриваются действительнозначные функции на отрезке действительной оси
	
	{\it Теорема о дифференцировании под пределом}
	
	$\forall k:$ функция $u_k(x)$ дифференцируема (имеет непрерывную производную) на отрезке $[a, b]$
	
	$\exists c \in [a, b]: u_k(c)$ сходится к конечному пределу
	
	$u_k^{\prime}(x)  \rightrightarrows \omega(x)$ на отрезке $[a, b]$
	
	Тогда $\exists u(x): u_k(x) \rightrightarrows u(x),\ u(x)$ -- дифференцируема на $[a, b],\ u^{\prime}(x) = \omega(x)$ на $[a, b]$
	
	{\it Теорема о почленном дифференцировании}

	$\forall k:$ функция $u_k(x)$ -- дифференцируема на отрезке $[a, b]$
	
	$\exists c \in [a, b]: \sum\limits_{k=1}^{\infty} u_k(c)$ сходится
	
	$\sum\limits_{k=1}^{\infty}u_k^{\prime}(x)$ равномерно сходится на отрезке $[a, b]$
	
	Тогда $\exists S(x): \sum\limits_{k=1}^{\infty}u_k(x) \rightrightarrows S(x),\ S(x)$ -- дифференцируем на $[a, b], S^{\prime}(x) = \sum\limits_{k=1}^{\infty}u_k^{\prime}(x)$ на $[a, b]$
	
\end{enumerate}

\subsubsection{Степенные ряды}

\D {{\bf Степенной ряд с одной переменной} -- это формальное алгебраическое вырадение вида $$F(x) = \sum\limits_{n=0}^{\infty}a_nX^n$$ в котором коэффициенты $a_n$ берутся из некоторого кольца $R$, обычно вещественные или комплексные числа}

Для степенных рядов есть несколько теорем об их сходимости

\begin{itemize}
	\item Певая теорема Абеля
	
	Пусть ряд $\sum a_n x^n$ сходится в точке $x_0$. Тогда этот ряд сходится абсолютно в круге $|x| < |x_0|$ и равномерно по $x$ на любом компактном подмножестве этого круга.
	
	Отсюда можно сделать вывод что если ряд расходится при $x = x_0$, то он расходится при всех $|x| > |x_0|$
	
	Появляется понятие радиуса сходимости $R$, при котором при $|x| < R$ ряд сходится абсолютно, про $|x| > R$ расходится
	
	\item Формула Коши-Адамара (Коши-Амидамару)
	
	 Значение радиуса сходимости степенного ряда может быть вычислено по формуле $\frac{1}{R} = \uplim\limits_{n \rightarrow +\infty}|a_n|^{1/n}$
	  
	 \item Признак Даламбера
	 
	 Если при $n > N$ и $\alpha > 1$ выполнено неравенство $|\frac{a_n}{a_{n+1}}| \ge R(1 + \frac{\alpha}{n})$ тогда степенной ряд $\sum a_n x^n$ сходится во всех точках окружности $|x| = R$ абсолютно и равномерно по $x$
	 
	 \item Признак Дирихле
	 
	 Если все коэффициенты степенного ряда $\sum a_n x^n$ положительны и последовательность $a_n$ монотонно сходится к 0б тогда этот ряд сходится во всех точках окружности $|x| = 1$, кроме, может быть, точки $x = 1$
\end{itemize}


\subsubsection{Ряд Тейлора}

\D {Ряд Тейлора -- разложение функции в бесконечную сумму степенных функций

Многочленом Тейлора функции $f(x)$ вещественной переменной $x$, дифференцируемой $k$ раз в точке $a$ называется конечная сумма 
$$f(x) = \sum\limits_{n=0}{k}\frac{f^{(n)}(a)}{n!} (x - a)^n = f(a) + f^{\prime}(a)(x - a) + \frac{f^{(2)}(a)}{2!}(x - a)^2 + ... + \frac{f^{(k)}(a)}{k!}(x - k)^k$$

Рядом Тейлора в точке $a$ функции $f(x)$ , бесконечно диффиренцируемой в окрестности точки $a$, называется формальный степенной ряд
$$f(x) = \sum\limits_{n=0}^{+\infty}\frac{f^{(n)}(a)}{n!}(x - a)^n$$

Другими словами, рядом Тейлора функции $f(x)$ в точке $a$ называется ряд разложения функции по положительным степеням двучлена $(x - a)$

}

Еще есть формула Тейлора, это просто частичная сумма ряда вроде как.

В случае $a = 0$ это все безобразие -- {\bf ряд Маклорена}


\subsection{Определители и их свойства. Системы линейных алгебраических уравнений и их исследование. Методы решения систем линейных алгебраических уравнений.}

\subsubsection{Определитель}

\D {Определитель -- скалярная величина, которая характеризует ориентированное "растяжение"\ или "сжатие" \  многомерного евклидова пространства после преобразования матрицей. Имеет смысл только для квадратных матриц. Стандартные обозначения -- $\det(A), |A|, \Delta (A)$ }

{\bf Определение через перестановки}

Для квадратной матрицы $A = (a_{ij})$ размера $n \times n$ ее определитель вычисляется по формуле $$det A = \sum\limits_{\alpha_1, \alpha_2, ..., \alpha_n}(-1)^{N(\alpha_1, \alpha_2, ..., \alpha_n)} \cdot a_{1 \alpha_1} a_{2 \alpha_2} ... a_{n \alpha_n}$$

Где суммирование проводится по всем перестановкам $\alpha_1, \alpha_2, ..., \alpha_n$ чисел $1, 2, ..., n$, а $N(\alpha_1, \alpha_2, ..., \alpha_n)$ обозначает число инверсий в перестановке $\alpha_1, ..., \alpha_n$

Таким образом в определитель входит $n!$ слагаемых.


{\bf Аксиоматическое построение}

Понятие определителя может быть введено на основе его свойств. А именно, определителем вещественной матрицы называется функция $det: \mathbb{R}^{n \times n} \rightarrow \mathbb{R}$, обладающая следующими тремя свойствами

\begin{itemize}
	\item $\det(A)$ -- кососимметрическая функция строк(столбцов) матрицы $A$, т.е. не меняется при четных перестановках аргументов
	\item $\det(A)$ -- полилинейная функция строк (столбцов) матрицы $A$
	\item $\det(E) = 1$, где $E$ -- единичная $n \times n$ матрица.
\end{itemize}

Еще свойства

\begin{enumerate}
	\item $\det E = 1$
	\item $\det cA = c^n \det A$
	\item $\det A^T = \det A$
	\item $\det(AB) = \det A \cdot \det B$
	\item $\det A^{-1} = (\det A)^{-1}$, причем матрица обратима тогда и только тогда, когда обратим ее определитель
	\item Существует ненулевое решение уравнения $AX = 0$ тогда и только тогда, когда $\det A = 0$ 
\end{enumerate}

\subsubsection{Системы линейных уравнений}

В классическом варианте коэффициенты при переменных, свободные члены и неизвестные считаются вещественными числами

Общий вид системы линейных алгебраических уравнений:

$$
{\begin{cases}a_{11}x_{1}+a_{12}x_{2}+\dots +a_{1n}x_{n}=b_{1}\\a_{21}x_{1}+a_{22}x_{2}+\dots +a_{2n}x_{n}=b_{2}\\\dots \\a_{m1}x_{1}+a_{m2}x_{2}+\dots +a_{mn}x_{n}=b_{m}\\\end{cases}}$$

где $m$ -- количество уравнений, а $n$ -- количество переменных.

Система называется {\bf однородной}, если все ее свободные члены ($b_i$) равны нулю, иначе -- {\bf неоднородной}

Система называется {\bf совместной}, если она имеет хотя бы одно решение, иначе несовместной. Решения считаются различными, если хотя бы одно из значений переменных не совпадает. Если решение одно, то система {\bf определенная}

Также есть запись в матричной форме

$
\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn} 
\end{pmatrix}
\begin{pmatrix}
	x_1 \\
	x_2 \\
	\vdots \\
	x_n
\end{pmatrix} 
=
\begin{pmatrix}
	b_1 \\
	b_2 \\
	\vdots \\
	b_m
\end{pmatrix}$

или $Ax=b$. Если к матрицу $A$ приписать справа столбец свободных членов, матрица будет называться расширенной.

Системы называются {\bf эквивалентными}, если множество их решений совпадает, т.е. если решение одной системы является решением другой.

Можно менять уравнения домножением на константу кроме 0, на сумму с другим уравнением, на линейную комбинацию с учетом этой. Будут получаться эквивалентные системы.

\subsubsection{Методы решения систем уравнений}

\begin{itemize}
	\item {\it Метод Гаусса}
	
	Приводим матрицу к ступенчатому виду, остались какие-то переменные. Назовем главными те, которые на диагонали, остальные -- свободные. Теперь переносим свободные через =, и присваивая им все возможные значения легко получить решения для главных, а значит для всей системы.
	
	Подробнее \href{https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%93%D0%B0%D1%83%D1%81%D1%81%D0%B0}{здесь}
		
	\item {\it Метод Гаусса-Жордана}
	
	\begin{enumerate}
		\item Выбирают первый слева столбец матрицы, в котором есть хоть одно отличное от нуля значение.
		\item Если самое верхнее число в этом столбце ноль, то меняют всю первую строку матрицы с другой строкой матрицы, где в этой колонке нет нуля.
		\item Все элементы первой строки делят на верхний элемент выбранного столбца.
		\item Из оставшихся строк вычитают первую строку, умноженную на первый элемент соответствующей строки, с целью получить первым элементом каждой строки (кроме первой) ноль.
		\item Далее проводят такую же процедуру с матрицей, получающейся из исходной матрицы после вычёркивания первой строки и первого столбца.
		\item После повторения этой процедуры $(n-1)$ раз получают верхнюю треугольную матрицу
		\item Вычитают из предпоследней строки последнюю строку, умноженную на соответствующий коэффициент, с тем, чтобы в предпоследней строке осталась только 1 на главной диагонали.
		\item Повторяют предыдущий шаг для последующих строк. В итоге получают единичную матрицу и решение на месте свободного вектора (с ним необходимо проводить все те же преобразования).
		
	\end{enumerate}

	Короче приводим к единичной, что осталось у свободных членов и есть решение
	
	\item {\it Метод Крамера}
	
	Для системы $n$ линейных уравнений с $n$ неизвестными (над произвольным полем)
	
	$\begin{cases}a_{11}x_{1}+a_{12}x_{2}+\ldots +a_{1n}x_{n}=b_{1}\\a_{21}x_{1}+a_{22}x_{2}+\ldots +a_{2n}x_{n}=b_{2}\\\cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \\a_{n1}x_{1}+a_{n2}x_{2}+\ldots +a_{nn}x_{n}=b_{n}\\
	\end{cases}$
	
	с определителем матрицы системы $\Delta$ , отличным от нуля, решение записывается в виде
	
	$ x_{i}={\frac {1}{\Delta }}{\begin{vmatrix}a_{11}&\ldots &a_{1,i-1}&b_{1}&a_{1,i+1}&\ldots &a_{1n}\\a_{21}&\ldots &a_{2,i-1}&b_{2}&a_{2,i+1}&\ldots &a_{2n}\\\ldots &\ldots &\ldots &\ldots &\ldots &\ldots &\ldots \\a_{n-1,1}&\ldots &a_{n-1,i-1}&b_{n-1}&a_{n-1,i+1}&\ldots &a_{n-1,n}\\a_{n1}&\ldots &a_{n,i-1}&b_{n}&a_{n,i+1}&\ldots &a_{nn}\\\end{vmatrix}}$
	(i-ый столбец матрицы системы заменяется столбцом свободных членов).
	
	Подставляем вместо соответствующего столбца свободные члены, считаем определитель, делим на определитель всей матрицы, и получаем $x_i$ соответствующий данному столбцу.
	
	\item {\it Матричный метод}
	
	Есть система вида $AX=B$, тогда решением будет $X=A^{-1}B$
	
	Чтобы работало, нужно чтобы матрица $A$ была невырождена, т.е. чтобы определитель был не равен 0
	
\end{itemize}

Еще есть какие-то итерационные и другие методы, но они звучат и выглядят не очень полезными, но можно посмотреть \href{https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B0_%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D1%8B%D1%85_%D0%B0%D0%BB%D0%B3%D0%B5%D0%B1%D1%80%D0%B0%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D1%85_%D1%83%D1%80%D0%B0%D0%B2%D0%BD%D0%B5%D0%BD%D0%B8%D0%B9#:~:text=%D0%A1%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B0%20%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D1%8B%D1%85%20%D0%B0%D0%BB%D0%B3%D0%B5%D0%B1%D1%80%D0%B0%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D1%85%20%D1%83%D1%80%D0%B0%D0%B2%D0%BD%D0%B5%D0%BD%D0%B8%D0%B9%20(%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F,%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D1%8B%D0%BC%20%E2%80%94%20%D0%B0%D0%BB%D0%B3%D0%B5%D0%B1%D1%80%D0%B0%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%BC%20%D1%83%D1%80%D0%B0%D0%B2%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5%D0%BC%20%D0%BF%D0%B5%D1%80%D0%B2%D0%BE%D0%B9%20%D1%81%D1%82%D0%B5%D0%BF%D0%B5%D0%BD%D0%B8}{тут}

\subsection{Линейные операторы в конечномерном пространстве и их матричноепредставление. Характеристический многочлен, собственные числа и собственные вектора линейного оператора. Сопряженные и самосопряженные операторы.}

\subsubsection{ Линейные операторы}

\D {Пусть $X$ и $Y$ -- линейные пространства над полем $F$. Отображение $\mathcal{A}: X \rightarrow Y$ называется линейным оператором, если $\forall x_1, x_2 \in X, \forall \lambda \in F$
\begin{itemize}
	\item $\mathcal{A}(x_1 + x_2) = \mathcal{A}(x_1) + \mathcal{A}(x_2)$
	\item $\mathcal{A}(\lambda \cdot x_1) = \lambda \cdot \mathcal{A}(x_1)$
\end{itemize}

Линейный оператор $\mathcal{A}: X \rightarrow X$ называется автоморфизмом (или гомоморфизмом)

}

Операторы равны, если переводят элементы первого пространства в одинаковые элементы второго пространства.

\D{Пусть $\mathcal{A}: X \rightarrow Y$

Пусть п.п. $X \leftrightarrow \{e_k\}_{k=1}^{n},\ \dim X = n$

Пусть п.п. $Y \leftrightarrow \{h_k\}_{k=1}^{n},\ \dim Y = m$

$\underset{{1\le k \le n}}{\mathcal{A}e_k} = \sum\limits_{i = 1}^{m} \alpha_k^i \cdot h_i \Rightarrow A = ||\alpha_k^i||,$ где $1 \le i \le m, 1 \le k \le m$

$A = \begin{pmatrix}
	\alpha_1^1 & ... & \alpha_n^1\\
	\alpha_1^2 & ... & \alpha_n^2\\
	... & ... & ...\\
	\alpha_1^n & ... & \alpha_n^n\\
	
\end{pmatrix}$

}

\subsubsection{Характеристический многочлен}

\D {Для данной матрицы $A$, $\chi(\lambda) = \det (A - \lambda E)$, где $E$ -- единичная матрица, является многочленом от $\lambda$, который называется {\bf характеристическим многочленом} матрицы $A$ (видимо можно отождествить матрицу с линейным оператором, тогда будет многочлен для оператора)}

Ценность характеристического многочлена в том, то собственные значения матрицы являются его корнями. Действительно, если уравнение $Av = \lambda v$ имеет ненулевое решение, то $(A - \lambda E)v = 0$, значит матрица $A - \lambda E$ вырождена и ее определитель $\det (A - \lambda E) = \chi(\lambda)$ равен 0

{\bf Свойства}

\begin{itemize}
	\item Для матрицы $n \times n$ характеристический многочлен имеет степень $n$
	\item Все корни характеристического многочлена матрицы являются ее собственными значениями
	\item Теорема Гамильтона-Кэли -- если $\chi(\lambda)$ -- характеристический многочлен матрицы $A$, то $\chi(A) = 0$
	\item Характеристические многочлены подобных матриц совпадают
	\item Характеристический многочлен обратной матрицы $\chi_{A^{-1}}(\lambda) = \frac{(-\lambda)^n}{\det A}\chi_A(1/\lambda)$
	\item Если $A$ и $B$ две матрицы $n \times n$, то $\chi_{AB} = \chi_{BA}$. В частности $tr(AB) = tr(BA), \det(AB) = \det (BA)$
	\item В более общем виде, если $A$ --матрица $m \times n$, а $B$ -- матрица $n \times m$, причем $m < n$, так что $AB$ и $BA$ --квадратные матрицы размеров $m$ и $n$ соответственно, то $\chi_{BA}(\lambda) = \lambda ^{n - m}\chi_{AB}(\lambda)$ 
\end{itemize}


\D{Пусть $L$ -- линейное пространство над полем $K$,

$\mathcal{A}:L \rightarrow L$ -- линейный оператор

{\bf Собственным вектором} линейного оператора $\mathcal{A}$ называется такой ненулевой вектор $x \in L$, что для некоторого $\lambda \in K: \mathcal{A}x = \lambda x$

При этом $\lambda$ называют {\bf собственным числом} оператора $\mathcal{A}$

}

{\bf Свойства}

\begin{itemize}
	\item Собственные векторы, отвечающие различным собственным значениям, образуют ЛНЗ набор
	\item Еще какие-то леммы есть, подробнее см на \href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%BE%D0%B1%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D0%B5_%D0%B2%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D1%8B_%D0%B8_%D1%81%D0%BE%D0%B1%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D0%B5_%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F}{говне}
\end{itemize}

\subsubsection{Сопряженные и самосопряженные операторы}

\D{Пусть $E, L$ -- линейные пространства, а $E^*, L^*$ -- сопряженные линейные пространства (пространства линейных функционалов, определенных на $E$ и $L$). Тогда для любого линейного оператора $\mathcal{A}: E \rightarrow L$ и любого линейного функционала $g \in L^*$ определен линейный функционал $F \in E^*$ -- суперпозиция $g$ и $A: f(x) = g(A(x))$. Отображение $g \rightarrow f$ называется сопряженным линейным оператором и обозначается $\mathcal{A^*}: L^* \rightarrow E^*$. Если кратко, то $(\mathcal{A^*}g, x) = (g, \mathcal{A}x)$
	
Если же $\mathcal{A^*} = \mathcal{A}$, то такой оператор называется самосопряженным, для него $(\mathcal{A}x, y) = (x, \mathcal{A}y)$
}

\subsection{Предмет и основные определения теории вероятностей.Классическое определение вероятности.Зависимые и независимые события. Условные и безусловные вероятности. Формула полной вероятности. Формула Байеса.}

\subsubsection{Теория вероятностей}

Классическое определение вероятности -- есть пространство событий, тогда вероятность события $A$ -- это отношение числа $m$ благоприятных этому событию случаев, к числу всех возможных случаев, т.е. $P(A) = \frac{m}{n}$

\D{ Два события $A$ и $B$ называются {\bf независимыми}, если $p(A \cap B) = p(A) \cdot p(B)$}

\D {Два события $A$ и $B$ называются {\bf несовместными}, если $A \cap B = \emptyset$}

\D{ {\bf Условная вероятность}: Пусть задано вероятностное пространство $(\Omega, P)$. Условной вероятностью события $A$ при условии, что произошло событие $B$, называется число 
	
$P(A | B) = \frac{P(A \cap B)}{P(B)}$, где $A, B \in \Omega$}

Если $P(B) = 0$, то определение неприменимо.

\subsubsection{Формула полной вероятности}

\D {Вероятность события $A \in \Omega$, которое может произойти только вмест с одним из событий $B_1, B_2, ..., B_n$, образующих полную систему событий, равна сумме произведений вероятностей гипотез на условные вероятности события, вычисленные соотвественно при каждой из гипотез

$P(A) = \sum\limits_{i=1}^n P(A | B_i)P(B_i)$
}

При этом полная система -- когда $B_i \cap B_j = \emptyset$, а $P(B_i) > 0, B_1 \cup ... \cup B_n = \Omega$

\subsubsection{Формула Байеса}

\D {Формула Байеса -- соотношение различных предполагаемых вероятностей различных событий, которое дает вероятность, что какое-то событие $A$ является результатом $X$ ряда независимых друг от друга событий $B_1, B_2, ..., B_n$, который, возможно, привел к $A$

$P(B_i|A) = \frac{P(A | B_i)P(B_i)}{P(A)}$

}

\subsection{Математическое ожидание случайной величины. Его смысл и примеры. Свойства математического ожидания. Дисперсия и среднее квадратическое отклонение случайной величины. Их смысл и примеры вычисления. Формулы для вычисления дисперсии. Свойства дисперсии}

\subsubsection{Математическое ожидание}

\D{ Пусть задано вероятностное пространство $(\Omega, \mathbb{P})$ и определенная на нем соучайная величина $X$, т.е. по определению $X: \Omega, \mathbb{R}$ -- измеримая функция. Если существует интеграл Лебега от $X$ по пространству $\Omega$, то он и называется матожиданием

$\mathbb{E}[X] = \int\limits_{\Omega} X(\omega)\mathbb{P}(d \omega)$

В дискретном случае выглядит как $\sum X(\omega) p(\omega)$
}

Смысл -- ожидаемое среднее значение если взять много сэмплов случайной величины и усреднить.

Пример: честная кость -- $E[X] = \frac{1}{6} \cdot 1 + ... + \frac{1}{6} \cdot 6 = 3.5$

{\bf Свойства}

\begin{itemize}
	\item $E(a) = a,$ где $a$ -- константа
	\item Если $0 \le \xi \le \eta$ и $\eta$ -- случайная величина с конечным матожиданием, то $0 \le E(\xi) \le E(\eta)$
	\item $\xi = \eta \Rightarrow E(\xi) = E(\eta)$
	\item Если $\xi$ и $\eta$ независимы, то $E(\xi \cdot \eta) = E(\xi) \cdot E(\eta)$
	\item Матожидание линейно, т.е. $E(aX + bY) = aE(X) + bE(Y)$
	
\end{itemize}

\subsubsection{Дисперсия}

\D {Дисперсией случайной величины называется матожидание квадрата отклонения этой величины от ее матоидания -- $DX = E(X - EX)^2$}

Можно по линейности переписать как $DX = EX^2 - (EX)^2$

{\bf Среднеквадратическое отклонение -- корень дисперсии $\sigma = \sqrt{DX}$}

Дисперсия характеризует разброс случайной величины вокруг ее матожидания. Среднеквадратичное отклонение используется для оценки масштаба возможного отклонения

{\bf Свойства}

\begin{itemize}
	\item Дисперсия неотрицательна
	\item Если дисперсия конечна, то конечно и матожидание
	\item Дисперсия константы равна 0 $Da = 0$, также верно обратное $DX = 0 \Rightarrow X = EX$ почти всюду
	\item $D(X + Y) = DX + DY + 2cov(X, Y)$, где $cov(X, Y) = E[(X - EX)(Y - EY)]$
	\item Для независимых величин ковариация равна 0
	\item $D(aX) = a^2DX$
	\item $D(-X) = DX$
	\item $D(X+b) = DX$
\end{itemize}


\subsection{ Дискретные случайные величины. Математическое ожидание и дисперсия. Стандартные дискретные распределения (Бернулли, биномиальное, геометрическое, Пуассона).}

\D { Случайная величина -- отображение из множества элементарных исходов в множество вещественных чисел}

\D { {\bf Дискретной случайной величиной} называется случайная величина, множество значений которой не более чем счетно, причем принятие ею каждого из значений есть случайное событие с определенной вероятностью}

\D {{\bf Функция распределения} случайной величины -- функция $F(x)$, определенная на $\mathbb{R}$ как $P(\xi \le x)$ т.е. выражаюшая вероятность того, что $\xi$ примет значение меньшее или равное $x$}

Матожидание дискретной величины -- $E\xi = \sum \xi_i p(\xi_i)$, где $\xi_i$ -- возможный исход, а $p_{\xi_i}$ -- его вероятность.

Дисперсия пересчитывается по формуле $DX = EX^2 - (EX)^2$

\subsubsection{ Стандартные дискретные распределения}

{\bf Распределение Бернулли}

Величина принимает всего 2 значения -- $1$ и $0$ с вероятностями $p$ и $q = 1 - p$ соответственно

{\bf Биноминальное распределение}

Это распределение количества "успехов" \ в последовательности из $n$ независимых случайных экспериментов, таких, что вероятность успеха в них одинакова и равна $p$.

Т.е. есть последовательность $X_1, ..., X_n$ -- независимых случайных величин имеющих распределение Бернулли с параметром $p$, тогда $Y = X_1 + ... + X_n$ имеет биноминальное распределени с параметрами $n$ и $p = Bin(n, p)$ 

В этом случае функция вероятности задается формулой $\mathbb{P}(Y = k) = {n \choose k} p^k q^{n - k}, k = 0, ..., n$

${n \choose k} = C_n^k = \frac{n!}{k!(n-k)!}$

{\bf Геометрическое распределение}

Одно из двух

\begin{enumerate}
	\item распределение вероятностей случайной величины $X$ равой номеру первого успеха в серии испытаний Бернулли и принимающей значение $n = 1, 2, 3,...$
	\item Распределение вероятностей случайной величины $Y = X - 1$ равной числу неудач до первого успеха, и принимающей значения $n = 0, 1, 2,...$
\end{enumerate}

В cлучае первого успеха $P(X = n) = (1 - p)^{n - 1}p$

В случае количества неудач -- $P(Y = n) = (1 - p)^n p$


{\bf Распределение Пуассона}

Распределение числа событий, произошедших за фиксированое время, при условии что они происходят с некоторой фиксированной средней интенсивностью и независимо друг от друга

Выберем фиксированное $\lambda > 0$ и определим дискретное распределение по функции вероятности:

$p(k) = P(Y = k) = \frac{\lambda^k}{k!}e^{-\lambda}$

где 

$k$ -- количество событий

$\lambda$ -- матожидание величины 



\subsection{Непрерывные случайные величины и их функции распределения. Математическое ожидание и дисперсия. Стандартные непрерывные распределения (равномерное, показательное, нормальное).}

\subsubsection{Непрерывные случайные величины}

\D { Непрерывной случайной величиной называют случайную величину, которая в результате испытания принимает все значения из некоторого числового промежутка. Число возможных значений непрерывной случайной величины бесконечно.}

$F_X(x) = P(X \le x)$


В непрерывном случае $\P(X = x) = 0 \forall x \in \mathbb{R}$
 и $F_X(x - 0) = F_X(x), \forall x \in \mathbb{R}$
 
А следовательно формулы имеют вид $P(X \in |a, b|) = F_X(b) - F_X(a)$



Матожидание для непрерывных величин считается по формуле $EX = \int\limits_{-\infty}^{+\infty}xf(x)dx$, где $f(x)$ -- функция плотности распределения (штука от которой интеграл равен 1, говорит с какой вероятностью выпадет то или иное значение (или отношение для разных значений в непрерывном случае))


Дисперсия же вычисляется по формуле $DX = \int\limits_{-\infty}^{+\infty} x^2 f(x) dx - (EX)^2$

\subsubsection{Стандартные равномерные распределения}

{\bf Равномерное распределение}

Распределение, которое принимает значения из некоторого промежутка конечной длины, при этом плотность вероятности на этом промежутке почти всюду постоянна.

Т.е. с равной вероятностью может выпасть любое значение из промежутка.

Плотность имеет вид $f_X(x) = \begin{cases}
\frac{1}{b - a}, x \in [a, b]\\
0, x \not\in [a, b]
\end{cases}$

{\bf Показательное (экспоненциальное) распределение}

Случайная величина имеет экспоненциальное распределение с параметром $\lambda > 0$, если ее плотность вероятности имеет вид

$f_X(x) = \begin{cases}
\lambda e^{-\lambda x}, x \ge 0\\
0, x < 0
\end{cases}$

{\bf Нормальное распределение}


Плотность вероятности $f(x) = \frac{1}{\sigma \sqrt{2 \pi}}e^{-\frac{1}{2}(\frac{x - \mu}{\sigma})^2}$

где $\mu$ -- матожидание

$\sigma$ -- среднеквадратическоее отклонение

Данное распределение моделирует ситуацию когда есть какое-то среднее и какая-то дисперсия, Наибольшая вероятность получить среднее, в зависимости от дисперсии получаем значения дальше или ближе к среднему.


\subsection{Вероятностные неравенства Йенсена, Маркова и Чебышёва. Правило трёх сигм. Закон больших чисел}

\subsubsection{Неравенство Йенсена}

\D {Пусть $(\Omega, \mathcal{F}, \mathbb{P})$ -- вероятностное пространство, и $X: \Omega \rightarrow \mathbb{R}$ -- определенная на нем случайная величина. Пусть также $\phi: \mathbb{R} \rightarrow \mathbb{R}$ -- выпуклая (вниз) борелевская функция. Тогда если $X, \phi(X) \in L^1 (\Omega, \mathcal{F}, \mathbb{P})$, то
$$\phi(EX) \le E(\phi(X))$$. Также можно добавить условность}

\subsubsection{Неравенство Маркова}

\D {Пусть неотрицательная случайная величина $X: \Omega \rightarrow \mathbb{R}^{+}$ определена на вероятностном пространстве, и ее матожидание конечно. Тогда 

$\mathbb{P}(X \ge a) \le \frac{EX}{a}$}

{\bf Док-во:}

Пусть неотрицательная лучайная величина $X$ имеет плотность распределения $p(x)$, тогда для $a > 0$

$EX = \int\limits_{0}^{\infty} xp(x)dx \ge \int\limits_{a}^{\infty}xp(x)dx \ge \int\limits_{a}^{\infty}ap(x)dx = a \mathbb{P}(X \ge a)$


\subsubsection{Неравенство Чебышева}

\D {Пусть случайная величина $X$ определена на вероятностном пространстве, а ее матожидание $\mu$ и дисперсия $\sigma^2$ конечны. Тогда

$P(|X - \mu| \ge a) \le \frac{\sigma^2}{a^2}, a > 0$

Если $a = k\sigma$, где $\sigma$ -- стандартное отклонение, $k > 0$, то получаем

$P(|X - \mu| >\ge k\sigma) \le \frac{1}{k^2}$
}


\subsubsection{Правило трех сигм}

Если случайная величина распределена нормально, то абсолютная величина ее отклонения от матожидания не превосходит утроенного среднего квадратического отклонения

$P(|X - \mu| \ge 3 \sigma) \le \frac{1}{9}$


\subsubsection{Закон больших чисел}

\D {Рассмотрим последовательность независимых в совокупности случайных величин $X_1, X_2, ...$ интегрируемых по Лебегу, которые имеют одинаковые распределения, следовательно, и одинаковые матожидания. Обозначим через $\overline{X}_n$ среднее арифметическое рассматриваемых случайных величин. Оно сходится к матожиданию}

{\bf Слабый закон}

Сходится по вероятности к матожиданию 

$\overline{X}_n \rightarrow \mu$ при $n \rightarrow 0$

\subsection{ Статистические оценки параметров распределения (сущность теории оценивания): несмещенность, состоятельность, эффективность оценок. Точечные оценки: выборочная средняя, дисперсия, среднее квадратическое отклонение.}


\subsubsection{Статистические оценки}

\D {Статистическая оценка -- то статисткика, которая используется для оценивания неизвестных параметров распределений сслучайной величины. Задача статистической оценки формулируется так

Пусть $\xi = (\xi_1, ..., \xi_n)$ -- выборка из генеральной совокупности с распределением $F_{\xi}(x, \theta)$. Распределение $F_{\xi}$ имеет известную функциональную форму, но зависит от неизвестного параметра $\theta$/ Этот параметр может быть любой точкой заданноко параметрического множества $\Theta$. Испольщуя статистическую информацию, содержащуюся в выборке $\xi$, сделать выводы о настоящем параметре значения $\theta$ }

Например посчитать матожидание как среднее арифметическое в предположении о нормальности.

Свойства оценок

\begin{itemize}
	\item Несмещенность -- если матожидание оценки совпадает с оцениваемым параметром $E\theta = \theta$
	\item Состоятельность -- При увеличении числа опытов оценка $\hat{\theta}$ сходится по вероятности к параметру $\theta$
	\item Эффективность -- Если дисперсия несмещенной оценки $D\hat{\theta}$ является минимальной по сравнению с другими оценками 
\end{itemize}

\subsubsection{Точечная оценка}

\D {Пусть $X_{1},\ldots ,X_{n},\ldots$  — случайная выборка для распределения, зависящего от параметра $\theta \in \Theta$ . Тогда статистику $\hat {\theta }(X_{1},\ldots ,X_{n})$, принимающую значения в $\Theta$, называют точечной оценкой параметра $\theta$ .}

\begin{itemize}
	\item Выборочное среднее -- Пусть $X_1, ..., X_n$ -- выборка из распределения вероятности, определеннная на некотором вероятностном пространстве. Тогда ее выборочным средним называется случайная величина $\overline{X} = \frac{1}{n}\sum X_i$
	
	Свойства: 
	\begin{itemize}
		\item ВЫборочное среднее -- несмещенная оценка теоретического среднего
		
		$E\overline{X} = E X_i, i = 1, ..., n$
		\item Выборочное среднее -- сильно состоятельная оценка теоретического среднего
		
		$\overline{X} \rightarrow E X_i $почти наверное при $n \rightarrow \infty$
		
		\item Выборочное среднее -- асимптотически нормальная оценка.
		
		Пусть дисперсия случайных величин $X_{i}$ конечна и ненулевая, то есть $\mathrm {D} [X_{i}]=\sigma ^{2}<\infty ,\sigma ^{2}\not =0,\;i=1,\ldots ,n$. Тогда
	    $\sqrt {n}\left({\overline {X}}-\mathbb {E} [X_{1}]\right)\to \mathrm {N} (0,\sigma ^{2})$ по распределению при $n\to \infty$ ,
		где $\mathrm {N} (0,\sigma ^{2})$ — нормальное распределение со средним $0$ и дисперсией $\sigma ^{2}$.
	\end{itemize}
	
	\item Выборочная дисперсия
	
	Пусть $X_{1},\ldots ,X_{n},\ldots$  — выборка из распределения вероятности. Тогда
	
	выборочная дисперсия — это случайная величина
	
	$S_{n}^{2}={\frac  {1}{n}}\sum \limits _{{i=1}}^{n}\left(X_{i}-{\bar  {X}}\right)^{2}={\frac  {1}{n}}\sum \limits _{{i=1}}^{n}X_{i}^{2}-\left({\frac  {1}{n}}\sum \limits _{{i=1}}^{n}X_{i}\right)^{2}$,
	
	где символ $\bar  {X}$ обозначает выборочное среднее;
	
	несмещённая (исправленная) дисперсия — это случайная величина
	
	$S^{2}={\frac  {1}{n-1}}\sum \limits _{{i=1}}^{n}\left(X_{i}-{\bar  {X}}\right)^{2}$.
	
	\item Среднеквадратическое отклонение 
	
	$\sum _{i=1}^{n}\left(x_{i}-{\bar {x}}\right)^{2}.$
\end{itemize}

\subsection{Интервальные оценки. Точность оценки. Доверительная вероятность. Доверительные интервалы для оценки неизвестного значения генеральной средней и генеральной доли.}

\subsubsection{Интервальная оценка}

\D {Пусть $ X=(X_{1},\ldots ,X_{n})$ — случайная выборка объёма $n$, порождённая случайной величиной с функцией распределения вероятностей $ F(x;\theta )$, известной с точностью до параметра $\theta \in \Theta$ . Располагая выборкой $X$, необходимо найти оценку $\hat {\theta }$ параметра $\theta \in \Theta$ . В общем случае имеется нулевая вероятность того, что $\hat {\theta }=\theta$ — что точечная оценка $\hat {\theta }$ совпадёт с параметром $\theta$ . Поэтому для оценивания параметра используется интервальная оценка.
	
Проблема состоит в нахождении на основании выборки статистик $\hat {\theta _{1}}={\hat {\theta _{1}}}(X_{1},\ldots ,X_{n})$, $ {\hat {\theta _{2}}}={\hat {\theta _{2}}}(X_{1},\ldots ,X_{n})$, которые с достоверностью удовлетворяют неравенству ${\hat {\theta _{1}}}<\theta <{\hat {\theta _{2}}}$. Зададимся достаточно малым числом $\alpha$  — уровнем значимости. Тогда интервал $ [{\hat {\theta _{1}}},{\hat {\theta _{2}}}]$ называется интервальной оценкой параметра $\theta $, если $ P({\hat {\theta _{1}}}<\theta <{\hat {\theta _{2}}})=1-\alpha $.
	
Интервал $ I(X)=[{\hat {\theta _{1}}}(X),{\hat {\theta _{2}}}(X)]$ называется доверительным интервалом параметра на уровне значимости $\alpha$ или с надежностью $1-\alpha$ .}

{\bf Точность оценки} -- положительное число $\delta > 0$ характеризующее величину расхождения оценками выборки и генеральной совокупности

$|\theta - \hat{\theta}| < \delta$

{\bf Надежностью (доверительной вероятностью)} оценки $\theta$ по $\hat{\theta}$ называют вероятность $\gamma$, с которой осуществляется неравенство $|\theta - \hat{\theta}| < \delta$. Обычно задается наперед, часто берут наджность близкую к единице.

Доверительные интервалы для генеральной средней  и доли \href{http://mathprofi.ru/ocenki_po_povtornoy_i_bespovtornoy_vyborke.html}{тут}

\subsection{Статистическая проверка гипотез. Статистическая гипотеза: параметрическая и
непараметрическая; нулевая и альтернативная. Ошибки I и II рода. Уровень
значимости и мощность критерия.}

\href{
	http://www.machinelearning.ru/wiki/index.php?title=%D0%9F%D1%80%D0%BE%D0%B2%D0%B5%D1%80%D0%BA%D0%B0_%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D1%85_%D0%B3%D0%B8%D0%BF%D0%BE%D1%82%D0%B5%D0%B7
}{Проверка статистических гипотез}

\D{
	\textbf{Параметрическая гипотеза} - делает предположение о том, что
	выборка получена из некоторого параметрического семейства распределений,
	и предполагает значение параметра.

	\textbf{Непараметрическая гипотеза} - не делает предположений о виде
	распределения.
}

\subsection{Статистический критерий проверки нулевой гипотезы. Наблюдаемое значение
критерия. Критическая область. Область принятия гипотезы. Критические точки.
Отыскание односторонней и двусторонней критических областей. Основные
этапы проверки статистических гипотез.}

\href{
	http://www.machinelearning.ru/wiki/index.php?title=%D0%9F%D1%80%D0%BE%D0%B2%D0%B5%D1%80%D0%BA%D0%B0_%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D1%85_%D0%B3%D0%B8%D0%BF%D0%BE%D1%82%D0%B5%D0%B7
}{Проверка статистических гипотез}

\href{
	https://studme.org/290347/matematika_himiya_fizik/otyskanie_levostoronney_dvustoronney_kriticheskih_oblastey
}{
	Отыскание критических областей.
}

\subsection{Множества и операции над ними. Булевы функции, КНФ, ДНФ. Базисы, теорема
Поста.}

\subsubsection{Множества и операции над ними}

\subsubsection{Булевы функции, КНФ, ДНФ}
\T{В ДНФ можно выразить любую функцию}
\begin{proof}
	Рассмотрим строчки таблицы истинности с 1, для каждой напишем клоз из $n$ лиетралов, который выполняет ровно эту строчку.
	
	Википедия чета пишет про то, что тождественный 0 нельзя представить. Вообще можно, если можно писать $x \wedge \neg x$
\end{proof}

\T{В КНФ можно выразить любую булеву функцию}
\begin{proof}
	Построим ДНФ к отрицанию, повесим отрицание, по де-Моргану получим КНФ 
\end{proof}

\subsubsection{Базисы, теорема Поста}

Булевы функции можно получать из других при помощи композиции. Возникает естественный вопрос, какими наборами функций можно выразить любую функцию.

\D{
	Стрелка Пирса: $x \uparrow y = \neg (x \vee y)$ 
}
\T{
	Стрелка Пирса - полный базис
}
\begin{proof}
	Получим конъюнкцию, дизъюнкцию и отрицание
	\begin{enumerate}
		\item $\neg x = x \uparrow x$
		\item $x \vee y = \neg (x \uparrow y)$
		\item $x \wedge y = \neq (\neg x \vee \neq y)$
	\end{enumerate}
\end{proof}

Вот Пост придумал критерий, как по набору функций понять, является ли он полным.

\textit{Замыкание класса функций} - это множество всех их возможных композиций.

Мы предъявляем 5 классов функций:
\begin{align*}
	T_0 = \{f \mid f(\overline{0}) = 0\}\\
	T_1 = \{f \mid f(\overline{1}) = 1\}\\
	M = \{f \mid \forall \alpha, \beta \in \mathbb{B}^n\ (\alpha \geq \beta) \rightarrow f(\alpha) \geq f(\beta)\}\\
	S = \{f \mid \forall \alpha \in \mathbb{B}^n f(\alpha) = \overline{f(\overline{\alpha})}\}\\
	L = \{f \mid f(x_1, x_2, \ldots x_n) = \alpha_0 \oplus \alpha_1x_1 \oplus \ldots \oplus \alpha_nx_n\}
\end{align*}

\T[Критерий поста]{
	Множество функций $F$ полно тогда и только тогда, когда в нем (его замыкании относительно композиций) есть функция, не принадлежащая ни одному из классов выше.
}

\begin{proof}
	Понятно, что если замыкание $F$ содержится в одном из классов, то $F$ не полно, т.к. ни один из классов не совпадает со множеством всех функций.
	
	В другую сторону докажем, что в $F$ можно реализовать конъюнкцию дизъюнкцию и отрицание. 
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.4]{images/post_sheme.png}
		\caption{Порядок перебора вариантов при доказательстве критерия Поста}
	\end{figure}
	
	Полное доказательство на \href{https://ru.wikipedia.org/wiki/%D0%9A%D1%80%D0%B8%D1%82%D0%B5%D1%80%D0%B8%D0%B9_%D0%9F%D0%BE%D1%81%D1%82%D0%B0}{Вики.}
\end{proof}


\subsection{Комбинаторные объекты. Коды Грея. Формула включения-исключения. Лемма Бернсайда и Теорема Пойа. Числа Стирлинга. Подсчёт деревьев. Метод производящих функций.}

\subsubsection{Коды Грея}
Код Грея - код для элементов упорядоченного множества (например, чисел от 1 до $n$), такой что расстояние Хэмминга между кодами соседних элементов = 1.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{images/grey.png}
\end{figure}

Коды Грея легко получаются из двоичных чисел путём побитовой операции «Исключающее ИЛИ» с тем же числом, сдвинутым вправо на один бит и в котором старший разряд заполняется нулём. Следовательно, $i$-й бит кода Грея $G_i$ выражается через биты двоичного кода $B_i$ следующим образом:
\begin{align*}
G_i = B_i \oplus B_i >> 1
\end{align*}

где $\oplus$ — операция «исключающее ИЛИ»; биты нумеруются справа налево, начиная с младшего. 

Декодинг происходит по формуле 
\begin{align*}
	B_i = B_{i + 1} \oplus G_i
\end{align*}

Код Грея назван «рефлексивным» (отражённым) из-за того, что первая половина значений при изменении порядка эквивалентна второй половине, за исключением старшего бита. Старший бит просто инвертируется. При делении каждой новой половины пополам это свойство сохраняется.

Код Грея используется в тех случаях, когда мы медленно считываем значения, а они меняются. Представим себе, что код (обычный двоичный) перескакивает $3\rightarrow4$, или $011_2 \rightarrow 100_2$. Если из-за несовершенства считывателя мы прочитаем первый бит от $011$, а остальные два — от $100$, мы получим $000_2=0$ — число, далёкое от реальных значений. В коде Грея никаких посторонних значений не будет: перескок будет в одном разряде, $010_G \rightarrow 110_G$, и мы считаем либо старое $010_G=3$, либо новое $110_G=4$. 

\subsubsection{Формула включения-исключения}

\T{
	Пусть $A = \bigcup\limits_{i = 1}^nA_i$, тогда по формуле включения-исключения:
	\begin{align*}
		|A| = \sum\limits_{I \in 2^N - 1}(-1)^{|I| + 1}|\bigcap_{j\in I}A_j|
	\end{align*}

	где $N = \{1, \ldots n\}$, $2^N - 1$ - множество всех непустых подмножеств $N$. 
}
\begin{proof}
	\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%A4%D0%BE%D1%80%D0%BC%D1%83%D0%BB%D0%B0_%D0%B2%D0%BA%D0%BB%D1%8E%D1%87%D0%B5%D0%BD%D0%B8%D1%8F-%D0%B8%D1%81%D0%BA%D0%BB%D1%8E%D1%87%D0%B5%D0%BD%D0%B8%D1%8F}{Доказательство}.
\end{proof}

Формулу включений исключений можно интерпретировать в вероятностном смысле, нужно лишь заменить множества на события, а мощности на вероятности. 

\subsubsection{Лемма Бернсайда}

\D{
	Говорят, что группа $G$ действует на множестве $M$ слева, если задано отображение $G \times M \rightarrow M$, такое что
	\begin{enumerate}
		\item $g(hm) = (gh)m$ для всех $g, h \in G, m \in M$
		\item $em = m$, где $e$ - нейтральный элемент $G$
	\end{enumerate}
}

\D{
	Подмножество
	\begin{align*}
		Gm = \{gm \mid g \in G\} \subset M
	\end{align*}

	Называется орбитой элемента $m$
}

\T[Лемма Бернсайда]{
	Пусть $G$ — конечная группа, действующая на множестве $X$. Тогда число орбит действия равно среднему количеству точек, фиксированных точек в $X$ элементами $G$.
	
	Точнее, для любого элемента $g \in G$ будем обозначать через $X^g$ множество элементов $X$, оставляемых на месте $g$, то есть
	\begin{align*}
		X^g = \{x \in X \mid gx = x\}
	\end{align*} 

	Тогда
	\begin{align*}
		|X/G| = \frac{1}{|G|}\sum\limits_{g \in G}|X^g|
	\end{align*}
	
	где $|X/G|$ - обозначает число орбит действия.
}
\begin{proof}
	\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9B%D0%B5%D0%BC%D0%BC%D0%B0_%D0%91%D1%91%D1%80%D0%BD%D1%81%D0%B0%D0%B9%D0%B4%D0%B0_%D0%B8_%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%9F%D0%BE%D0%B9%D0%B0#.D0.A2.D0.B5.D0.BE.D1.80.D0.B5.D0.BC.D0.B0_.D0.9F.D0.BE.D0.B9.D0.B0}{Доказательство}.
\end{proof}


\subsubsection{Теорема Пойа}
\href{https://e-maxx.ru/algo/burnside_polya}{Тут} максимально просто написано и про Пойа и про Бернсайда.

\subsubsection{Числа Стирлинга}
\begin{itemize}
	\item \textit{Первого рода.} Количество перестановок из $n$ элементов с $k$ циклами.
	
	Можно посчитать рекурсивно:
	\begin{align*}
		c(n, k) = c(n - 1, k - 1) + (n - 1)\cdot c(n - 1, k)
	\end{align*} 
	\item \textit{Второго рода.} Количество неупорядоченных разбиений $n$-элементного множества на $k$ непустых подмножеств.
	
	Можно посчитать рекурсивно:
	\begin{align*}
		S(n, k) = S(n - 1, k - 1) + k\cdot S(n - 1, k)
	\end{align*}
	
	Есть явная формула:
	\begin{align*}
		S(n, k) = \frac{1}{k!}\sum\limits(-1)^{k + j}{k \choose j}j^n
	\end{align*}
\end{itemize}

\subsubsection{Подсчет деревьев}
\D{
	$n$-ое число Каталана:
	\begin{align*}
		C_n = \frac{1}{n + 1}\binom{2n}{n}
	\end{align*}

	Числа Каталана - удовлетворяют рекуррентному соотношению
	\begin{align*}
		C_0 = 1\\
		C_n = \sum\limits_{i =0}^{n - 1}C_iC_{n - 1 - i}
	\end{align*}
	Например, это количество правильных скобочных последовательностей длины $2n$.
}

Более подробно на \href{https://ru.wikipedia.org/wiki/%D0%A7%D0%B8%D1%81%D0%BB%D0%B0_%D0%9A%D0%B0%D1%82%D0%B0%D0%BB%D0%B0%D0%BD%D0%B0}{Вики}.

\T{
	Количество неизоморфных упорядоченных бинарных деревьев с корнем и $n + 1$ листьями = $n$-ому числу Каталана. 
	
	Здесь \textit{упорядоченные} означает, что ребра, выходящие из каждой вершины, упорядочены.
}

\D{
	Помеченное дерево c $n$ вершинами - дерево c $n$ вершинами, вершинам которого взаимно однозначно соответствуют числа от 1 до $n$.
}

\T[Кэли]{
	Число помеченных деревьев с $n$ вершинами равняется $n^{n - 2}$.
}
\begin{proof}
	Доказательство и еще много всего интересного смотри \href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D0%BE%D0%B4%D1%81%D1%87%D0%B5%D1%82_%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D1%8C%D0%B5%D0%B2}{тут}. 
\end{proof}

\subsubsection{Метод производящих функций}
Вот \href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%BE%D0%B4%D1%8F%D1%89%D0%B0%D1%8F_%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F}{отсюда} можно прочитать определение и пример для решения рекуррент


\subsection{Детерминированные и недетерминированные конечные автоматы, их эквивалентность. Минимизация ДКА.}
\D{
	Формально КА определяется как пятёрка:
	
	$A=(S,X,Y,\delta ,\lambda )$
	
	где 
	\begin{itemize}
		\item $S$ — конечное множество состояний автомата
		\item $X,Y$ — конечные входной и выходной алфавиты соответственно, из которых формируются строки, считываемые и выдаваемые автоматом
		\item $\delta :S\times X\rightarrow S$ — функция переходов
	 	\item $\lambda :S\times X\rightarrow Y$ — функция выходов
	\end{itemize}

	Можно добавить $s_0 \in S$ - начальное состояние.
	
	При анализе КА принято полагать, что конечный автомат начинает работу в некотором начальном состоянии $q_{0}$, последовательно получает по одному символу из входного слова (цепочки входных символов). Считанный символ может перевести автомат в новое состояние или не перевести в новое состояние в соответствии с функцией переходов.
	
	Получая входную цепочку символов $x$ и делая переходы из состояния в состояние, автомат после получения последнего символа входного слова окажется в некотором состоянии $q'$.
	
	Если это состояние является заключительным, то говорят, что автомат допустил слово $x$.
	
	Автомат называется конечным в силу конечности множества внутренних состояний.
}

Различают детерминированные КА — автоматы, в которых следующее состояние однозначно определяется текущим состоянием и выход зависит только от текущего состояния и текущего входа, и недетерминированные КА, следующее состояние у которых в общем случае неопределённо и, соответственно, не определён выходной сигнал. Если переход в последующие состояния происходит с некоторыми вероятностями, то такой КА называют вероятностным КА. 

\begin{figure}[H]
	\centering
	\begin{minipage}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{images/dfa.png}
		\caption{Пример графа переходов детерминированного КА.}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{images/ndfa.png}
		\caption{Пример графа переходов недетерминированного КА с самопроизвольными переходами.}
	\end{minipage}
\end{figure}

\begin{itemize}
	\item Детерминированным конечным автоматом (ДКА) называется такой автомат, в котором нет дуг с меткой $\varepsilon$ (предложение, не содержащее ни одного символа), и из любого состояния по любому символу возможен переход не более, чем в одно состояние
	\item Недетерминированный конечный автомат (НКА) является обобщением детерминированного. Недетерминированность автоматов может достигаться двумя способами: либо могут существовать переходы из состояния в состояние, вызываемые пустой цепочкой символов, то есть самопроизвольные переходы без внешних воздействий, либо из одного состояния КА может переходить в разные состояния под воздействием одного и того же символа.
	
	Также недетерменированность может достигаться за счет не единственного (а множества) начальных состояний.
\end{itemize}

\D{
	Говорят, что детерменированный автомат принимает слово, если обработав его, он приходит в специальное конечное состояние. 
	
	Недетерменированный принимает, если \underline{существует} последовательность, такая что принимает.
}

\D{
	Язык автомата - множество принимаемых слов.
}

\T[О детерминизации]{
	Для любого недетрменированного конечного автомата может быть построен эквивалентный (с тем же языком) детерменированный автомат. 
}
\begin{proof}
	План:
	\begin{enumerate}
		\item Удалить все $\varepsilon$-переходы
		\begin{enumerate}[a]
			\item Удалить все состояния, в которые приходят только $\varepsilon$-ребра
			\item Соединить напрямую $p \rightarrow_a q$, если есть путь $p \rightsquigarrow_\varepsilon r \rightarrow_a q$
			\item Конечными делаем те состояния, из которых достижимы конечные по $\varepsilon$-ребрам
		\end{enumerate}
		\item Делаем исходящую степень $\leq 1$.
		
		Для этого множеством новых состояний положим множество всех подмножеств старых состояний. 
		
		Функция переходов нового конечного автомата определена так, что из состояния-множества $S$ по входному символу $а$ конечный автомат $M_1$ переходит в состояние-множество, представляющее собой объединение всех множеств состояний старого конечного автомата, в которые этот старый конечный автомат переходит по символу $а$ из каждого состояния множества $S$. Таким образом, конечный автомат $M_1$ является детерминированным по построению.
	\end{enumerate}

	Более подробно:  \href{http://mathhelpplanet.com/static.php?p=determinizatsiya-konechnykh-avtomatov}{Доказательство}.
	
	Заметим, что размер автомата может раздуться экспоненциально. 
\end{proof}

\subsubsection{Минимизация ДКА}

Минимизация ДКА — построение по детерминированному конечному автомату (ДКА) эквивалентного ДКА, имеющего наименьшее возможное число состояний. 

\T{
	Для любого регулярного языка существует минимальный ДКА, который его принимает, то есть, ДКА с наименьшим возможным числом состояний. Такой автомат единственен с точностью до изоморфизма. 
}

А вот дальше реально прикол, готовьтесь
\T{
	Пусть $\mathcal {A}$ — ДКА. Обозначим через $r({\mathcal {A}})$ инвертированный автомат $\mathcal {A}$. Через  $d({\mathcal {A}})$ обозначим детерминизированный автомат, полученный из $\mathcal {A}$ процедурой построения подмножеств. Имеет место следующий результат:
	
	Пусть автомат $\mathcal {A}$ распознаёт язык $L$. Тогда минимальный ДКА для языка $L$ может быть найден как $\mathcal {A}_{L}=drdr({\mathcal {A}})$.
}

\subsubsection{Регулярные языки}
\D{
	Пусть $\Sigma$ - конечный алфавит. Регулярными языками над $\Sigma$ называются языки, получаемые по следующим правилам:
	\begin{enumerate}
		\item Пустое множество - регулярный язык
		\item Множество, состоящие из пустой строки - регулярный язык
		\item Множество вида $\{a\}, a \in \Sigma$ - регулярный язык
		\item Если $\alpha, \beta$ - регулярные языки, то 
		\begin{itemize}
			\item $\alpha \cup \beta$
			\item Конкатенация $\alpha\beta$
			\item Взятие звездочки Клини $\alpha^*$
		\end{itemize}
		 - регулярные языки, где
		 
		 Звезда Клини языка $\alpha$ - минимальное множество слов, полученых конкатенацией слов из $\alpha$ и пустой строки. 
	\end{enumerate}
}

\T[Клини]{
	Язык является регулярным тогда и только тогда, когда он допускается некоторым конечным автоматом, используемым в этом языке. 
}


\subsection{Контекстно-свободные грамматики. Эффективные методы разбора: LL(k)-, LR(k)- и LALR-грамматики.}

\D{
	Формальная грамматика (англ. Formal grammar) — способ описания формального языка, представляющий собой четверку
	
	$\Gamma = \langle \Sigma, N, S \in N, P\rangle$
	
	, где:
	\begin{itemize}
		\item $\Sigma$ — алфавит, элементы которого называют терминалами (англ. terminals);
		\item $N$ — множество, элементы которого называют нетерминалами (англ. nonterminals);
		\item $S$ — начальный символ грамматики (англ. start symbol);
		\item $P$ — набор правил вывода (англ. production rules или productions) $\alpha \rightarrow \beta$.
	\end{itemize}
}

\D{
	Левосторонним выводом слова (англ. leftmost derivation) $\alpha$ называется такой вывод слова $\alpha$, в котором каждая последующая строка получена из предыдущей путем замены по одному из правил самого левого встречающегося в строке нетерминала.
}

Контекстно-свободная грамматика: \href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9A%D0%BE%D0%BD%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BD%D0%BE-%D1%81%D0%B2%D0%BE%D0%B1%D0%BE%D0%B4%D0%BD%D1%8B%D0%B5_%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B8,_%D0%B2%D1%8B%D0%B2%D0%BE%D0%B4,_%D0%BB%D0%B5%D0%B2%D0%BE-_%D0%B8_%D0%BF%D1%80%D0%B0%D0%B2%D0%BE%D1%81%D1%82%D0%BE%D1%80%D0%BE%D0%BD%D0%BD%D0%B8%D0%B9_%D0%B2%D1%8B%D0%B2%D0%BE%D0%B4,_%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE_%D1%80%D0%B0%D0%B7%D0%B1%D0%BE%D1%80%D0%B0}{neerc}.

Наша задача - понять принадлежит ли входное слово языку. Для этого нам нужно предъявить вывод из стартового нетерминала. 
\begin{itemize}
	\item $LR(k)$-анализатор просматривает символы слева направо, складывает их в стек. Если в стеке накопилась правая часть какого-то правила, нужно принимать решение: заменять ли содержание стека на левую часть этого правила или ждать еще, чтоб накопилась правая часть еще какого-то правила (являющаяся надстрокой для текущей гипотезы). Чтобы принять это решение, анализатор смотрит еще $k$ символов.
	
	\href{https://neerc.ifmo.ru/wiki/index.php?title=LR(k)-%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B8}{neerc}
	
	\item $LL(k)$-анализатор
	
	\href{https://neerc.ifmo.ru/wiki/index.php?title=LL(k)-%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B8,_%D0%BC%D0%BD%D0%BE%D0%B6%D0%B5%D1%81%D1%82%D0%B2%D0%B0_FIRST_%D0%B8_FOLLOW}{neerc}
	
	\item \href{https://ru.wikipedia.org/wiki/SLR(1)}{$SLR(1)$ грамматика} - это грамматика, в которой усовершенствованно построение таблицы $LR(0)$ грамматики при помощи применения FIRST и FOLLOW (см. $LL$-анализатор).
	
	\href{https://ru.wikipedia.org/wiki/LALR(1)}{$LALR(1)$} - усовершенствование $SLR(1)$
\end{itemize}


\subsection{Комбинаторная теория сложности. Временная и емкостная сложность.
Сложностные классы P, NP, PS. Сведение, NP-полные задачи}

\href{
	http://www.machinelearning.ru/wiki/index.php?title=%D0%92%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D1%81%D0%BB%D0%BE%D0%B6%D0%BD%D0%BE%D1%81%D1%82%D1%8C
}{Вычислительная сложность}

\href{https://ru.wikipedia.org/wiki/%D0%A1%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5_(%D1%82%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D1%81%D0%BB%D0%BE%D0%B6%D0%BD%D0%BE%D1%81%D1%82%D0%B8_%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D0%B9)}{Сведение}

\href{
	https://ru.wikipedia.org/wiki/NP-%D0%BF%D0%BE%D0%BB%D0%BD%D0%B0%D1%8F_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0
}{NP-comp}


\subsection{Марковские цепи, Эргодические цепи, Регулярные цепи. Алгоритм Витерби.}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%B0%D1%8F_%D1%86%D0%B5%D0%BF%D1%8C}{Марковская цепь}

На состояниях Марковской цепи можно построить ориентированный граф.
\D{
	Эргодическая цепь Маркова - цепь, имеющая сильно связный граф. 
}
\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%AD%D1%80%D0%B3%D0%BE%D0%B4%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BC%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%B0%D1%8F_%D1%86%D0%B5%D0%BF%D1%8C}{Эргодическая цепь}

\D{
	Цепь регулярна тогда и только тогда, когда существует такое $n$, что в матрице $P^n$ все элементы ненулевые, то есть из любого состояния можно перейти в любое за $n$ переходов.
}
\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%BD%D0%B0%D1%8F_%D0%BC%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%B0%D1%8F_%D1%86%D0%B5%D0%BF%D1%8C}{Регулярная цепь}.

\subsubsection{Алгоритм Витерби}
\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%BA%D1%80%D1%8B%D1%82%D1%8B%D0%B5_%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8}{Скрытая Марковская цепь}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%92%D0%B8%D1%82%D0%B5%D1%80%D0%B1%D0%B8}{Алгоритм Витерби}

\subsection{Линейные структуры данных. Амортизационный анализ. Поисковые структуры данных. Запросы на отрезках. Персистентные структуры данных.}

Линейные структуры данных:
\begin{itemize}
    \item стек
    \item очередь
    \item дек
    \item массив
\end{itemize}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BC%D0%BE%D1%80%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7}{Амортизационный анализ}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D0%BE%D0%B8%D1%81%D0%BA%D0%BE%D0%B2%D1%8B%D0%B5_%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D1%8B_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85}{Поисковые структуры данных}

\href{https://e-maxx.ru/algo/segment_tree}{Запросы на отрезках}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D0%B5%D1%80%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B5_%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D1%8B_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85}{Персистентные структуры данных}


\subsection{Графы. Обход графов. Поиск кратчайших путей. Задача о паросочетании, максимальном потоке и максимальном потоке минимальной стоимости.}

Обход графов:
\begin{itemize}
    \item dfs
    \item bfs
\end{itemize}

Поиск кратчайших путей:
\begin{itemize}
    \item \href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%94%D0%B5%D0%B9%D0%BA%D1%81%D1%82%D1%80%D1%8B}{Дейкстра}
    находит кратчайший путь от одной из вершин графа до всех остальных. Алгоритм работает только для графов без рёбер отрицательного веса.
    \item \href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%A4%D0%BE%D1%80%D0%B4%D0%B0-%D0%91%D0%B5%D0%BB%D0%BB%D0%BC%D0%B0%D0%BD%D0%B0}{Форд-Беллман}
    находит кратчайшие пути от одной вершины графа до всех остальных во взвешенном графе. Вес рёбер может быть отрицательным. (сообщает о цикле отрицательного веса)
    \item \href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%A4%D0%BB%D0%BE%D0%B9%D0%B4%D0%B0}{Флойд (Уоршел)}
    находит кратчайшие пути между всеми вершинами взвешенного ориентированного графа (ищет цикл отрицательного веса)
    \item \href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%94%D0%B6%D0%BE%D0%BD%D1%81%D0%BE%D0%BD%D0%B0}{Джонсон}
    находит кратчайшие пути между всеми парами вершин взвешенного ориентированного графа. (Форд-Беллман + потенциальные функции)
\end{itemize}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D0%B0%D1%80%D0%BE%D1%81%D0%BE%D1%87%D0%B5%D1%82%D0%B0%D0%BD%D0%B8%D1%8F:_%D0%BE%D1%81%D0%BD%D0%BE%D0%B2%D0%BD%D1%8B%D0%B5_%D0%BE%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F,_%D1%82%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%BE_%D0%BC%D0%B0%D0%BA%D1%81%D0%B8%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%BC_%D0%BF%D0%B0%D1%80%D0%BE%D1%81%D0%BE%D1%87%D0%B5%D1%82%D0%B0%D0%BD%D0%B8%D0%B8_%D0%B8_%D0%B4%D0%BE%D0%BF%D0%BE%D0%BB%D0%BD%D1%8F%D1%8E%D1%89%D0%B8%D1%85_%D1%86%D0%B5%D0%BF%D1%8F%D1%85}{Паросочетания}

Поиск паросочетания в двудольном графе
\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%9A%D1%83%D0%BD%D0%B0_%D0%B4%D0%BB%D1%8F_%D0%BF%D0%BE%D0%B8%D1%81%D0%BA%D0%B0_%D0%BC%D0%B0%D0%BA%D1%81%D0%B8%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BF%D0%B0%D1%80%D0%BE%D1%81%D0%BE%D1%87%D0%B5%D1%82%D0%B0%D0%BD%D0%B8%D1%8F}{Алгоритм Куна}
\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%A4%D0%BE%D1%80%D0%B4%D0%B0-%D0%A4%D0%B0%D0%BB%D0%BA%D0%B5%D1%80%D1%81%D0%BE%D0%BD%D0%B0_%D0%B4%D0%BB%D1%8F_%D0%BF%D0%BE%D0%B8%D1%81%D0%BA%D0%B0_%D0%BC%D0%B0%D0%BA%D1%81%D0%B8%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BF%D0%B0%D1%80%D0%BE%D1%81%D0%BE%D1%87%D0%B5%D1%82%D0%B0%D0%BD%D0%B8%D1%8F}{Форд-Фалкерсон}

Паросочетания можно искать за $O(V^3)$ в произвольном графе с помощью \href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%B2%D1%8B%D1%80%D0%B5%D0%B7%D0%B0%D0%BD%D0%B8%D1%8F_%D1%81%D0%BE%D1%86%D0%B2%D0%B5%D1%82%D0%B8%D0%B9}{алгоритма вырезания соцветий}, но это так, чисто чтоб выебнуться.

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9E%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81%D0%B5%D1%82%D0%B8,_%D0%BF%D0%BE%D1%82%D0%BE%D0%BA%D0%B0}{Поток}

Максимальный поток ищем \href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%A4%D0%BE%D1%80%D0%B4%D0%B0-%D0%A4%D0%B0%D0%BB%D0%BA%D0%B5%D1%80%D1%81%D0%BE%D0%BD%D0%B0,_%D1%80%D0%B5%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_%D1%81_%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E_%D0%BF%D0%BE%D0%B8%D1%81%D0%BA%D0%B0_%D0%B2_%D0%B3%D0%BB%D1%83%D0%B1%D0%B8%D0%BD%D1%83}{Фордом-Фалкерсоном}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D0%BE%D1%82%D0%BE%D0%BA_%D0%BC%D0%B8%D0%BD%D0%B8%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B9_%D1%81%D1%82%D0%BE%D0%B8%D0%BC%D0%BE%D1%81%D1%82%D0%B8}{MinCostMaxFlow}


\subsection{Строки. Поиск строки в подстроке. Бор, алгоритм Ахо-Корасика. Суффиксные массивы и деревья.}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%9A%D0%BD%D1%83%D1%82%D0%B0-%D0%9C%D0%BE%D1%80%D1%80%D0%B8%D1%81%D0%B0-%D0%9F%D1%80%D0%B0%D1%82%D1%82%D0%B0}{Кнут-Моррис-Прат}
Объединяем строки через сепаратор, считаем префикс-функцию.

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D0%BE%D0%B8%D1%81%D0%BA_%D0%BF%D0%BE%D0%B4%D1%81%D1%82%D1%80%D0%BE%D0%BA%D0%B8_%D0%B2_%D1%81%D1%82%D1%80%D0%BE%D0%BA%D0%B5_%D1%81_%D0%B8%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5%D0%BC_%D1%85%D0%B5%D1%88%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F._%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%A0%D0%B0%D0%B1%D0%B8%D0%BD%D0%B0-%D0%9A%D0%B0%D1%80%D0%BF%D0%B0}{Рабин-Карп}
Хешируем паттерн и подстроку той же длины, проверяем хеши на равенство.

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%91%D0%BE%D1%80}{Бор}
Тупа префиксное дерево.

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%90%D1%85%D0%BE-%D0%9A%D0%BE%D1%80%D0%B0%D1%81%D0%B8%D0%BA}{Ахо-Корасик}
Хотим искать много паттернов в тексте. Строим по паттернам бор, добавляем суфф-ссылки
сжимаем их и получаем автомат, которым проходимся по тексту.

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D1%83%D1%84%D1%84%D0%B8%D0%BA%D1%81%D0%BD%D1%8B%D0%B9_%D0%BC%D0%B0%D1%81%D1%81%D0%B8%D0%B2}{Суффмасс}

\href{https://e-maxx.ru/algo/suffix_array}{Суффмасс emax}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%B6%D0%B0%D1%82%D0%BE%D0%B5_%D1%81%D1%83%D1%84%D1%84%D0%B8%D0%BA%D1%81%D0%BD%D0%BE%D0%B5_%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE}{Суффдерево}


\subsection{Постановка задачи линейного программирования. Двойственность задачи ЛП.}

\href{https://ru.wikipedia.org/wiki/%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%BE%D0%B5_%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5}{Постановка задачи}

\href{https://ru.wikipedia.org/wiki/%D0%94%D0%B2%D0%BE%D0%B9%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F}{Двойственность}


\subsection{Градиентные методы. Метод сопряжения градиентов. Минимизация квадратичных функций. Метод Ньютона.}

\href{https://ru.wikipedia.org/wiki/%D0%93%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B5_%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D1%8B}{Градиентные методы}

\href{http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D1%81%D0%BE%D0%BF%D1%80%D1%8F%D0%B6%D1%91%D0%BD%D0%BD%D1%8B%D1%85_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BE%D0%B2}{Метод сопряженных градиентов}

Вроде для минимизации квадратичных функций применяются все те же градиентные методы.

\D{
	Квадратичная функция - функция вида $F(x) = x^TAx + x^Tb + c$, где $A$ - симметричная матрица. (все это векторы, умножение скалярное, в итоге получается число) 
}

\href{https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%9D%D1%8C%D1%8E%D1%82%D0%BE%D0%BD%D0%B0}{Метод Ньютона}

\href{https://ru.algorithmica.org/cs/numerical/newton/}{Вот здесь} про Ньютона приятнее, чем на Вики


\subsection{Теория кодирования. Блоковые коды и их параметры. Критерии декодирования
и метрики. Границы Хемминга и Варшамова-Гилберта.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%9A%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%B8#.D0.9A.D0.BE.D0.B4
}{Кодирование информации}

\href{
	https://ru.wikipedia.org/wiki/%D0%91%D0%BB%D0%BE%D1%87%D0%BD%D1%8B%D0%B9_%D0%BA%D0%BE%D0%B4
}{Блоковые коды}

\href{https://docs.google.com/document/d/1Q9Q3T_WhroC04ByS0BtFDbvEZ6DrQbuFPd7fAl2XSWM/edit#heading=h.y6j1v1w9p3kd}{Билеты от ИС}

\href{
	https://ru.wikipedia.org/wiki/%D0%93%D1%80%D0%B0%D0%BD%D0%B8%D1%86%D0%B0_%D0%A5%D1%8D%D0%BC%D0%BC%D0%B8%D0%BD%D0%B3%D0%B0
}{Граница Хэмминга}

\href{
	https://ru.wikipedia.org/wiki/%D0%93%D1%80%D0%B0%D0%BD%D0%B8%D1%86%D0%B0_%D0%92%D0%B0%D1%80%D1%88%D0%B0%D0%BC%D0%BE%D0%B2%D0%B0_%E2%80%94_%D0%93%D0%B8%D0%BB%D0%B1%D0%B5%D1%80%D1%82%D0%B0
}{Граница Варшамова-Гилберта}


\subsection{CRISP-DM. Устройство данных.}

\href{
	https://ru.wikipedia.org/wiki/CRISP-DM
}{crisp-dm}

\subsection{Версионирование данных}

\href{
	https://drive.google.com/file/d/1stLNbKM8nhGtKo_hY_c91DIdlU1SRfFs/view
}{Какая-то помойка про 7 подходов}


\subsection{Feature engineering, корреляция, категориальные признаки, аугментация данных}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%A3%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B5%D0%BD%D0%B8%D0%B5_%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D0%B8#.D0.92.D1.8B.D0.B1.D0.BE.D1.80_.D0.BF.D1.80.D0.B8.D0.B7.D0.BD.D0.B0.D0.BA.D0.BE.D0.B2
}{Отбор признаков}

\href{
	https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%BF%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA%D0%BE%D0%B2
}{Конструирование признаков}

\textbf{Скоррелированность признаков} приводит к мультиколлинеарности (=).
Чтоб найти используют коэфф. корелляции пирсона.


\textbf{Кодирование категориальных признаков:}
\begin{itemize}
	\item label encoding = $cat \to \{0, 1, 2, ...\}$
	\item One Hot = $cat \to \prod\limits_1^n \{0, 1\}$
	\item Binary = $cat \to \{0, 1\}^n$
	\item Target encoding = использует целевую метку для кодирования
	категориального признака: среднее по классу, вероятность положительного
	класса.
	\item Contrast encoding = $cat \to \mathbb{R}^{n-1}$ - всякая помойка
	с матрицами
\end{itemize}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B8_%D1%80%D0%B5%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D1%85_%D1%81%D0%B5%D1%82%D0%B5%D0%B9#.D0.90.D1.83.D0.B3.D0.BC.D0.B5.D0.BD.D1.82.D0.B0.D1.86.D0.B8.D1.8F_.D0.B4.D0.B0.D0.BD.D0.BD.D1.8B.D1.85
}{Аугментация данных}


\subsection{Метрики оценки качества алгоритмов анализа данных}

\href{
	https://ml-handbook.ru/chapters/model_evaluation/intro#%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F-%D0%BF%D0%BE%D1%82%D0%B5%D1%80%D1%8C-neq-%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D0%BA%D0%B0-%D0%BA%D0%B0%D1%87%D0%B5%D1%81%D1%82%D0%B2%D0%B0
}{Метрики от яндекса}

\hyperref[sec:quality_measures]{Билет 4}

\subsection{Временные ряды: сезонность, периодичность, тренд. Стационарность, способы
приведения к стационарному виду.}

\href{
	https://storage.yandexcloud.net/emkn/private/3/courses/2021-spring/SP-machine-learning-2/slides/machine_learning_2_lecture_120221.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=YCAJEMFjtZXt0XJq57jJdKQB_%2F20220807%2Fru-central-1a%2Fs3%2Faws4_request&X-Amz-Date=20220807T171839Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=4892afb3332f043092bf2edd835e9f11f14eab973d66b10df9a0e6418ef8ea9d
}{Сухочев}

Тренд - долгосрочное изменение уровня ряда (на всем времени)

Сезонность - циклические изменения уровня ряда с постоянным периодом.

\textbf{Стационарность} = предполагает отсутствие тренда и сезонности.

$p(y_t, ..., y_T) = p(y_{t+\tau}, ..., y_{T+\tau})$

При гетероскедастичности можно прологарифмировать данные.

\href{
	https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D1%81%D1%82_%D0%94%D0%B8%D0%BA%D0%B8_%E2%80%94_%D0%A4%D1%83%D0%BB%D0%BB%D0%B5%D1%80%D0%B0
}{Дики-Фуллер: тест на Стационарность}

\textbf{Приведение к стационарному:}
\begin{itemize}
	\item Удаление тренда = дифференцирование: $y_t' = y_t - y_{t-1}$
	\item Гетероскедастичность = преобразование Бокса-Кокса
\end{itemize}


\subsection{Алгоритмы прогнозирования временных рядов}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D1%85_%D1%80%D1%8F%D0%B4%D0%BE%D0%B2
}{neerc} Но там нихуя не понятно.


\subsection{Постановка задачи обучения с учителем. Недообучение и переобучение,
дисбаланс классов, примеры моделей}

\hyperref[sec:supervised_learning]{Билет 2}

\href{
	http://www.machinelearning.ru/wiki/index.php?title=%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D0%B5%D0%BC
}{mlru}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D0%B5%D1%80%D0%B5%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5
}{overfitting/underfitting}

\href{
	https://machinelearningmastery.ru/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/
}{Дисбаланс классов}


\subsection{Задача уменьшения размерности: постановка, алгоритмы}

\hyperref[sec:dim_reduction]{Dimensionality reduction}


\subsection{Векторное представление объекта, векторные операции}


\subsection{Анализ изображений: алгоритмы выделения признаков, фильтры, pattern
matching}

\href{
	https://ru.wikipedia.org/wiki/%D0%92%D1%8B%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BF%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA%D0%BE%D0%B2#%D0%9E%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9
}{Выделение признаков no-ml}

\href{
	https://en.wikipedia.org/wiki/Template_matching#Feature-based_approach
}{ML feature extraction}

Свертки с фильтрами

\href{
	https://habr.com/ru/post/208090/
}{Всякое про фильтрацию}


\subsection{Анализ изображений: свёртки, эмбеддинги изображений, transfer learning}

Свертка = прикладываем везде фильтр и считаем скалярное произведение.

Эмбеддинги изображений можно получать из глубоких CNN.

\href{
	https://en.wikipedia.org/wiki/Template_matching#Feature-based_approach
}{ML feature extraction}

Transfer learning широко применяется для обучения эмбеддингов:
тренируем сетку классифицировать ImageNet, затем дообучаем на нашей задаче.


\subsection{Анализ текстовых данных: предобработка, tf-idf, обучение эмбеддингов слов}

\subsubsection{Предобработка}

\begin{itemize}
	\item Токенизация
	\item Удаление стоп-слов
	\item Стемминг - удаление окончаний
	\item Лемматизация - приведение к начальной форме
	\item Векторизация
\end{itemize}

\subsubsection{tf-idf}

\href{
	https://ru.wikipedia.org/wiki/TF-IDF
}{tf-idf}

Используется как коэффициент в представлении Bag of Words.

\subsubsection{Обучение эмбеддингов}

\hyperref[sec:word_embeddings]{Билет из 2 половины}


\subsection{Анализ звуковых данных: представление звука в ЭВМ, аугментация звука,
удаление тишины. методы извлечения признаков из аудио}

\href{
	https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%B7%D0%B2%D1%83%D0%BA%D0%BE%D0%B2%D0%BE%D0%B9_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%B8
}{Кодирование звука}

Для аугментаций можно применять фильтры и разные звуковые эффекты.

Для удаления тишины хуйнем фильтр по амплитуде.

\href{
	https://zen.yandex.ru/media/nuancesprog/analiz-audiodannyh-s-pomosciu-glubokogo-obucheniia-i-python-chast-1-5f05940552908058fabd38a3
}{Извлечение признаков}


\subsection{MapReduce. Определение, примеры решаемых задач, последовательная
реализация, распределённая реализация (в общих чертах).}

\href{
	https://ru.wikipedia.org/wiki/MapReduce#:~:text=MapReduce%20%E2%80%94%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D1%91%D0%BD%D0%BD%D1%8B%D1%85%20%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D0%B9%2C%20%D0%BF%D1%80%D0%B5%D0%B4%D1%81%D1%82%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F,%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D0%B0%D0%BC%D0%B8%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85%20%D0%B2%20%D0%BA%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D0%BD%D1%8B%D1%85%20%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B0%D1%85.
}{MapReduce def, example, есть немного про распределенную реализацию}


\subsection{MapReduce. Определение, примеры решаемых задач, каскады.
Combiner-оптимизация и примеры её применения.}

\href{
	https://blog.matthewrathbone.com/2015/06/25/real-world-hadoop-implementing-a-left-outer-join-in-java-with-cascading.html
}{cascades}

\href{
	https://coderlessons.com/tutorials/bolshie-dannye-i-analitika/izuchit-kartu-umenshit/mapreduce-combiners
}{Combiner}


\subsection{MapReduce. Join, tf-idf, сортировка}


\subsection{Spark. Модель программирования, RDD vs Dataframe, ленивость,
материализация датасетов.}


\subsection{Распределённое машинное обучение. Логистическая регрессия и её
распределённая реализация.}




% ==========================================================================
% 
% ==========================================================================

\section{Машинное обучение}

\subsection{Понятие машинного обучения в искусственном интеллекте. Классификация задач
машинного обучения, их примеры и особенности.}

\D{
    Машинное обучение - класс методов искусственного интеллекта,
    характерной чертой которых является не прямое решение задачи,
    а обучение за счёт применения решений множества сходных задач.
}

По имеющейся совокупности прецедентов (пар "объект" - "ответ") требуется
восстановить неявную зависимость, построить алгоритм, способный для любого
входного объекта выдать достаточно точный ответ.

Классификация задач машинного обучения:
\begin{itemize}
    \item \textbf{Обучение с учителем} - для каждого прецедента задается пара "ситуация, требуемое решение"
    \item \textbf{Обучение без учителя} - для каждого прецедента задаётся только
    «ситуация», требуется сгруппировать объекты в кластеры, используя данные
    о попарном сходстве объектов, и/или понизить размерность данных.
    \item \textbf{Обучение с подкреплением} - способ машинного обучения, при котором
    система обучается, взаимодействуя с некоторой средой.
    \item \textbf{Semi-supervised learning} - для части примеров известны ответы, а для части нет
\end{itemize}

Классические задачи машинного обучения:
\begin{itemize}
    \item Классификация
    \item Кластеризация
    \item Регрессия
    \item Понижение размерности
    \item Восстановление плотности распределения вероятности
\end{itemize}

\subsection{Задача обучения с учителем, классификация задач обучения с учителем, метод
минимизации эмпирического риска.}
\label{sec:supervised_learning}

Пусть $X$ - множество описаний объектов, $Y$ - множество допустимых ответов.
Существует неизвестная целевая зависимость $y^*: X \to Y$, значения которой
известны только на объектах конечной обучающей выборки $X^m = \{(x_1, y_1)\dots (x_m, y_m)\}$.

Требуется построить алгоритм $a: X \to Y$, который приближал бы неизвестную
зависимость как на элементах выборки, так и на всем множестве $X$.

Типы задач обучения с учителем:
\begin{itemize}
    \item Классификация = $|Y| < \infty$
    \item Регрессия = $|Y| = \infty$
\end{itemize}

Вводится функция потерь $\mathcal{L}(y, y')$, характеризующая величину
отклонения ответа $y = a(x)$ от правильного ответа $y' = y^*(x)$ на
произвольном объекте $x \in X$.

Вводится функционал качества, характеризующий среднюю ошибку
(эмпирический риск) алгоритма $a$ на произвольной выборке $X^m$:

$Q(a, X^m) = \frac{1}{m}\sum\limits_{i=1}^m \mathcal{L}(a(x_i), y^*(x_i))$

\textbf{Метод минимизации эмпирического риска} заключается в том, чтобы
в заданной модели алгоритмов $A = \{a: X \to Y\}$ найти алгоритм, минимизирующий
среднюю ошибку на обучающей выборке:

$a^* = arg \min\limits_{a \in A} Q(a, X^m)$

Тем самым задача сводится к оптимизации и может быть решена численными методами.


\subsection{Понятие переобучения и методы борьбы с ним.}

Обобщающая способность. Говорят, что алгоритм обучения обладает способностью
к обобщению, если вероятность ошибки на тестовой выборке достаточно
мала или хотя бы предсказуема, то есть не сильно отличается от ошибки
на обучающей выборке.

\D {
	Переобучение (англ. overfitting) — негативное явление, возникающее,
	когда алгоритм обучения вырабатывает предсказания, которые слишком
	близко или точно соответствуют конкретному набору данных и поэтому
	не подходят для применения алгоритма к дополнительным данным или
	будущим наблюдениям.
}

Методы борьбы с переобучением
\begin{itemize}
	\item Увеличение количества данных в наборе
	\item Уменьшение количества параметров модели
	\item Добавление регуляризации
\end{itemize}


\subsection{Меры оценки качества для классификации и регрессии.}
\label{sec:quality_measures}

\subsubsection{Оценка качества классификации}

\begin{table}[h!]
	\begin{tabular}{|c|c|c|}
		\hline
		& $y = 1$ & $y = 0$ \\
		\hline
		$a(x) = 1$ & TP & FP \\
		\hline
		$a(x) = 0$ & FN & TN \\
		\hline
	\end{tabular}
	\caption{Confusion matrix}
\end{table}

\D{
	\textbf{Accuracy} = доля верных ответов алгоритма.

	$Acc = \frac{TP + TN}{TP + FP + TN + FN}$
}

\D{
	\textbf{Precision} = доля объектов действительно принадлежащих данному
	классу среди всех объектов, отнесенных моделью к данному классу.

	$Precision = \frac{TP}{TP + FP}$

	По confusion matrix: отношение диагонального элемента к сумме строки.
}

\D{
	\textbf{Recall} = какую долю объектов, реально относящихся к положительному
	классу мы предсказали верно.

	$Recall = \frac{TP}{TP + FN}$

	По confusion matrix: отношение диагонального элемента к сумме столбца.
}

\D{
	$F = \frac{2 \times Precision \times Recall}{Precision + Recall}$
}

\D{
	\textbf{ROC-curve} = Позволяет рассмотреть все пороговые значения для
	данного классификатора. Показывает долю ложно положительных примеров
	(англ. false positive rate, FPR) в сравнении с долей истинно положительных
	примеров (англ. true positive rate, TPR). 

	Может давать неадекватную оценку при несбалансированности классов.
}

$TPR = Recall = \frac{TP}{TP + FN}$

$FPR = \frac{FP}{FP + TN} = 1 - TNR$, $TNR = specificity$

Прямая диагональная линия соответствует чисто случайному классификатору.
Хороший классификатор характеризуется большей площадью под кривой.

\D{
	\textbf{PR-curve} = x - полнота, y - точность.
}

\subsubsection{Оценка качества регрессии}

\begin{itemize}
	\item $MSE = \frac{1}{n} \sum\limits_1^n (a(x_i) - y_i)^2$ - позволяет сравнивать модели, но
	не позволяет определить, насколько хорошо алгоритм решает задачу.
	\item $MAE = \frac{1}{n} \sum\limits_1^n |a(x_i) - y_i|$ - менее чувствителен к выбросам.
	\item $R^2 = 1 - \frac{\sum\limits_1^n (a(x_i) - y_i)^2}{\sum\limits_1^n (y_i - \overline{y})^2}$ -
	Коэффициент детерминации измеряет долю дисперсии, объясненную моделью, в общей дисперсии целевой
	переменной. Фактически, данная мера качества — это нормированная среднеквадратичная ошибка. Если
	она близка к единице, то модель хорошо объясняет данные, если же она близка к нулю, то прогнозы
	сопоставимы по качеству с константным предсказанием.
	\item $MAPE = 100\% \times \frac{1}{n}\sum\limits_1^n \frac{|y_i - a(x_i)|}{|y_i|}$ - процент
	который составляет ошибка от фактических значений.
	\item $RMSE = \sqrt{\frac{1}{n} \sum\limits_1^n (a(x_i) - y_i)^2}$
\end{itemize}


\subsection{Метод ближайших соседей. Метод ядерного сглаживания (непараметрическая
регрессия)}

\subsubsection{Метод ближайших соседей}

\D{
	\textbf{Метрический классификатор} = алгоритм классификации основанный на вычислении
	оценок сходства между объектами.

	\textbf{kNN} = классифицируемый объект относится к тому классу, к которому
	принадлежит большинство его соседей (k ближайших элементов обучающей выборки).
}

Пусть на множестве объектов задана функция расстояния $\rho(x, x')$, тогда
любой новый объект $u$ задает порядок на обучающей выборке
$\rho(u, x_{1; u}) \leq \rho(u, x_{2; u}) \leq ... \leq \rho(u, x_{m; u})$

Алгоритм ближайших соседей: $a(u) = argmax_{y \in Y} \sum\limits_{i=1}^m
[y_{i;u} = y] w(i, u)$, где $w(i, u)$ - весовая функция, которая определяет
степень важности i-того соседа для классификации объекта $u$.

\begin{itemize}
	\item $w(i, u) = [i = 1]$ - метод 1 ближайшего соседа.
	\item $w(i, u) = [i \leq k]$ - метод k ближайших соседей.
	\item $w(i, u) = [i \leq k]q^i$ - метод k экспоненциально взвешенных ближайших соседей, $q < 1$
	\item $w(i, u) = K\left(\frac{\rho(u, x_{i; u})}{h}\right)$ - метод парзеновского окна фиксированной ширины h.
	\item $w(i, u) = K\left(\frac{\rho(u, x_{i; u})}{\rho(u, x_{k+1; u})}\right)$ -
	метод парзеновского окна переменной ширины.
	\item $w(i, u) = K\left(\frac{\rho(u, x_{i; u})}{h(x_{i; u})}\right)$ -
	метод потенциальных функций, в котором ширина окна $h(x_i)$ зависит не от
	классифицируемого объекта, а от обучающего объекта $x_i$.
\end{itemize}

Здесь $K(r)$ - ядро сглаживания = неотрицательная, монотонно невозрастающая функция на $[0, +\infty)$

Примеры ядер:
\begin{itemize}
	\item $1 - |r|$
	\item $\frac{3}{4}(1 - r^2)$
	\item $\frac{70}{81} (1 - |r|^3)^3$
\end{itemize}

\subsubsection{Метод ядерного сглаживания}

\textbf{Ядро} = непрерывная ограниченная симметричная вещественная функция
$K$, т.ч. $\int K (u) du = 1$

Представляет собой построение весовой функции $W_{mi} (x)$, определенной
на всех элементах обучающей выборки. Затем эти веса используются для
представления $a(x)$ в виде взвешенной суммы $y_i$.

$a(x) = argmax_{y \in Y} \sum [y_i = y] W_{mi} (x_i)$

Короче то же самое, что и кнн с ядрами.


\subsection{Метод градиентного спуска, усовершенствования метода градиентного
спуска.Линейная регрессия. Сингулярное разложение векторов.}

\subsubsection{Градиентный спуск}

Решает задачу поиска минимума функции $f: \mathbb{R}^n \to \mathbb{R}$ для
функций, у которых можно вычислить градиент.

Основная идея метода заключается в том, чтобы осуществлять оптимизацию
в направлении скорейшего спуска, которое задается антиградиентом $-\nabla f$.

$x_{k+1} = x_k - \lambda_k \nabla f(x_k)$

Критерии останова:
\begin{itemize}
	\item $||x_{k+1} - x_{k}|| \leq \varepsilon$
	\item $||f(x_{k+1}) - f(x_k)|| \leq \varepsilon$
\end{itemize}

Выбор LR = $\lambda_k$:
\begin{itemize}
	\item $\lambda_k = const$
	\item Пока условие $f(x_{k+1}) = f(x_k - \lambda_k f'(x_k)) \leq
	f(x_k) - \varepsilon\lambda_k ||f'(x_k)||^2$ выполняется $\lambda_k$
	остается константным, иначе $\lambda_{k+1} = \lambda_k \cdot \delta$
	- метод дробного шага.
	\item Метод наискорейшего спуска: $\lambda_k = arg 
	\min\limits_{\lambda \in [0, +\infty)} f(x_k - \lambda f'(x_k))$
\end{itemize}

\subsubsection{Линейная регрессия}

\D{
	\textbf{Линейная регрессия} - метод восстановления зависимости
	одной переменной от других с линейной функцией зависимости.
}

Для заданного множества пар $\{(x_i, y_i)\}$ значений свободной и зависимой
переменной требуется построить зависимость.

Назначена линейная модель с аддитивной случайной величиной $\varepsilon$:

$y_i = f(w, x_i) + \varepsilon_i$

Предполагается, что $\varepsilon$ распределена нормально с нулевым матожиданием
и фиксированной дисперсией $\sigma^2$, не зависящей от $x, y$. При таких
предположениях параметры $w$ регрессионной модели вычисляются методом наименьших
квадратов.

\begin{itemize}
	\item $f_1(x), ..., f_n(x)$ - числовые признаки объектов.
	\item $f(w, x) = \sum\limits_1^n w_j f_j(x)$ - линейная модель.
\end{itemize}

\begin{equation}
	F =
	\begin{pmatrix}
		f_1(x_1) & ... & f_n(x_1) \\
		... & ... & ... \\
		f_1(x_m) & ... & f_n(x_m)
	\end{pmatrix},
	y = 
	\begin{pmatrix}
		y_1 \\
		\vdots \\
		y_m
	\end{pmatrix},
	w =
	\begin{pmatrix}
		w_1 \\
		\vdots \\
		w_n
	\end{pmatrix}
\end{equation}

МНК:

$Q(w, X^m) = \sum\limits_{i=1}^m (f(w, x_i) - y_i)^2 = ||F w - y||^2 \to_w \min$

$\frac{d Q}{d w} = 2F^T(F w - y) = 0$ - условие минимума.

$\Rightarrow F^T F w = F^T y \Rightarrow w^* = (F^T F)^{-1}F^T y = F^+ y$

\subsubsection{Сингулярное разложение}

\T{
	У любой матрицы $A$ размера $n \times m$ существует разложение на
	матрицы $U, \Sigma, V^T: A_{n \times m} = U_{n \times n} \times \Sigma_{n \times m} \times V^T_{m \times m}$,
	где матрицы $U, V$ являются ортогональными ($U U^T = U^T U = E$),
	а матрица $\Sigma$ - диагональной.
}

Столбцы $U$ - собственные векторы матрицы $F F^T$, столбцы $V$ - собственные
векторы матрицы $F^T F$.

$F = VDU^T$

$F^+ = (U D V^T V D U^T)^{-1} U D V^T = U D^{-1} V^T = \sum\limits_1^n
\frac{1}{\sqrt{\lambda_j}} u_j v_j^T$

$w^* = \sum\limits_1^n \frac{1}{\sqrt{\lambda_j}} u_j (v_j^T y)$


\subsection{Метод опорных векторов для линейно разделимой выборки. Ядра и ядерный
трюк в методе опорных векторов.}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%BF%D0%BE%D1%80%D0%BD%D1%8B%D1%85_%D0%B2%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BE%D0%B2_(SVM)}{SVM}


\subsection{Вероятностная постановка задачи классификации и оптимальный
байесовский классификатор.Непараметрический метод оценки плотности.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%91%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B0%D1%8F_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F
}{Вероятностная постановка + опт байес}

\href{
	http://www.machinelearning.ru/wiki/index.php?title=%D0%9E%D1%86%D0%B5%D0%BD%D0%B8%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%BF%D0%BB%D0%BE%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%B8_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F
}{
	Метод оценки плотности (непарам)
}


\subsection{Параметрический метод оценки плотности и метод максимального
правдоподобия.}

\href{
	http://www.machinelearning.ru/wiki/index.php?title=%D0%9E%D1%86%D0%B5%D0%BD%D0%B8%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%BF%D0%BB%D0%BE%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%B8_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F
}{
	Метод оценки плотности и метод макс правдоподобия
}

\subsection{Логистическая регрессия.}

\href{http://www.machinelearning.ru/wiki/index.php?title=%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F}{
	Logreg
}


\subsection{Логические правила и вывод закономерностей. Деревья принятия решений.}


\subsection{Задача бустинга и градиентный бустинг. AdaBoost и его теоретические свойства.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%91%D1%83%D1%81%D1%82%D0%B8%D0%BD%D0%B3,_AdaBoost
}{
	Бустинг, adaboost
}

\href{
	https://logic.pdmi.ras.ru/~sergey/teaching/mlstc12/16-boosting.pdf
}{
	Теоретические свойства AdaBoost
}


\subsection{Случайный лес и стэкинг.}

\D{
	\textbf{Стэкинг} - метод ансамблирования моделей, при котором учитываются
	ответы всех моделей (например как среднее или majority vote)
}

При стекинге обучающую выборку делят на 2: на первой обучают базовые алгоритмы,
на второй получают мета-признаки из базовых алгоритмов и обучают метаалгоритм.

\href{
	https://learnmachinelearning.fandom.com/ru/wiki/%D0%90%D0%BD%D1%81%D0%B0%D0%BC%D0%B1%D0%BB%D0%B8_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B5%D0%B9#%D0%A1%D1%82%D1%8D%D0%BA%D0%B8%D0%BD%D0%B3_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B5%D0%B9
}{Стэкинг}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%94%D0%B5%D1%80%D0%B5%D0%B2%D0%BE_%D1%80%D0%B5%D1%88%D0%B5%D0%BD%D0%B8%D0%B9_%D0%B8_%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D1%8B%D0%B9_%D0%BB%D0%B5%D1%81#.D0.A1.D0.BB.D1.83.D1.87.D0.B0.D0.B9.D0.BD.D1.8B.D0.B9_.D0.BB.D0.B5.D1.81
}{Случайный лес}


\subsection{Нейрон Маккалока-Питтса, выразительная мощность нейрона. Многослойная
нейронная сеть и алгоритм обратного распространения ошибок.}

\href{http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C_%D0%9C%D0%B0%D0%BA%D0%9A%D0%B0%D0%BB%D0%BB%D0%BE%D0%BA%D0%B0-%D0%9F%D0%B8%D1%82%D1%82%D1%81%D0%B0}{Нейрон Маккалока-Питтса}

Модель Маккалока-Питтса эквивалентна пороговому линейному классификатору.

Одиночный нейрон строит линейную разделяющую поверхность в пространстве
признаков.

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8,_%D0%BF%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD}{Нейронные сети, перцептрон}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9E%D0%B1%D1%80%D0%B0%D1%82%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B8}{Backprop}


\subsection{Декомпозиция обратного распространения ошибок. Граф вычислений для
глубокой нейронной сети.}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9D%D0%B0%D1%81%D1%82%D1%80%D0%BE%D0%B9%D0%BA%D0%B0_%D0%B3%D0%BB%D1%83%D0%B1%D0%BE%D0%BA%D0%BE%D0%B9_%D1%81%D0%B5%D1%82%D0%B8}{Граф вычислений}


\subsection{Аугментация данных, дропаут и активационные функции для глубоких нейронных
сетей.}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B8_%D1%80%D0%B5%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D1%85_%D1%81%D0%B5%D1%82%D0%B5%D0%B9}{Все}


\subsection{Методы второго порядка и их применение в логистической регрессии.}

\href{http://www.machinelearning.ru/wiki/index.php?title=%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F_%28%D0%BF%D1%80%D0%B8%D0%BC%D0%B5%D1%80%29}{Пример}

\href{http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BA%D0%B0%D1%81%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D1%85_%28%D0%9D%D1%8C%D1%8E%D1%82%D0%BE%D0%BD%D0%B0-%D0%A0%D0%B0%D1%84%D1%81%D0%BE%D0%BD%D0%B0%29}{Метод Ньютона-Раффсона}

\subsection{Предобработка данных для глубоких нейронных сетей, инициализация Xavier и
He.}

\subsubsection{Предобработка}

Нормализация

Кодирование категориальных признаков:
\begin{itemize}
	\item label encoding = $cat \to \{0, 1, 2, ...\}$
	\item One Hot = $cat \to \prod\limits_1^n \{0, 1\}$
	\item Binary = $cat \to \{0, 1\}^n$
	\item Target encoding = использует целевую метку для кодирования
	категориального признака: среднее по классу, вероятность положительного
	класса.
	\item Contrast encoding = $cat \to \mathbb{R}^{n-1}$ - всякая помойка
	с матрицами
\end{itemize}

\subsubsection{Инициализация весов}

Нулями инициализировать плохо, т.к. все сигналы будут неактивированы.

\textbf{Xavier:}

Метод стремится сохранить дисперсию весов при переходе между слоями.
Хорошо работает с сигмоидными и линейными функциями активации.

Веса сэмплируются из равномерного или нормального распределений с дисперсией

$Var(W) = \frac{2}{n_{in} + n_{out}}$, где n - количество нейронов на предыдущем
и следующем слоях.

\textbf{He:}

Вариация предыдущего метода, лучше преспособленная для работы с ReLU
активациями.

В данном случае $Var(W) = \frac{2}{n_{in}}$


\subsection{Проблемы градиентного спуска. Улучшенные методы оптимизации: Momentum,
Nesterov accelerated gradient.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%9D%D0%B0%D1%81%D1%82%D1%80%D0%BE%D0%B9%D0%BA%D0%B0_%D0%B3%D0%BB%D1%83%D0%B1%D0%BE%D0%BA%D0%BE%D0%B9_%D1%81%D0%B5%D1%82%D0%B8
}{Кратко про модификации градиентного спуска}

Главная проблема: если разные переменные имеют разный масштаб, или по
разным координатам расстояние до целевой точки сильно отличается, то
становится сложно подобрать скорость сходимости, т.к. по части переменных
мы уже сошлись, а по другим - еще нет.

\subsubsection{With Momentum}

В обычном методе моментов хотим сохранить часть предыдущего апдейта.

$v_{t} = \alpha v_{t-1} - \eta \frac{\partial L(w_t)}{\partial w_t}$

$w_{t+1} = w_t + v_t$

\subsubsection{Nesterov accelerated gradient}

Если мы знаем, что хотим сохранить движение с предыдущего шага, то мы
можем считать новый градиент(вектор движения) в точке, перенесенной в
соответствии с сохранившимся движением.

$v_t = \gamma v_{t-1} - \mu \frac{\partial L (w_t - v_{t-1})}{\partial w_t}$

$w_{t+1} = w_t + v_t$


\subsection{Проблемы градиентного спуска. Улучшенные методы оптимизации: Adagrade,
RMSProp, Adadelta.}

Предыдущие оптимизации градиентного спуска рассматривают градиент как
единый вектор направления для всех переменных. Хотим различать скорость
изменения для всех переменных.

\subsubsection{Adagrade}

На пальцах: замедляемся на крутых склонах чтоб не перепрыгивать минимум,
ускоряемся на пологих, чтобы сходиться быстрее.

$G_0 = \overline{0}$

$G_{t,i} = G_{t-1, i} + g^2_{t, i}$, где $g_t = \nabla_w f(w_t)$

$w_{t+1} = w_t - \frac{\alpha}{\sqrt{G_t + \varepsilon}} g_t$

Проблема Adagrade заключается в том, что скорость обучения не может
увеличиться.

\subsubsection{RMSProp}

Улучшает Adagrad, позволяя забывать часть истории может увеличивать
скорость шага.

$G_{t, i} = \gamma G_{t-1, i} + (1 - \gamma) g^2_{t, i}$

$w_{t+1} = w_t - \frac{\alpha}{\sqrt{G_t + \varepsilon}} g_t$

Если посмотреть на величины, то получим несовпадение размерностей.

\subsubsection{Adadelta}

Убирает несовпадение размерностей.

$w_{t+1} = w_t - \alpha \frac{\sqrt{R_t + \varepsilon}}{\sqrt{G_t + \varepsilon}} g_t$

$R_{t, i} = \rho R_{t-1, i} - (1-\rho) (\delta_t w_i)^2$


\subsection{Проблемы градиентного спуска. Улучшенные методы оптимизации: Adam.}

Adam = RMSProp + Momentum

$w_{t+1} = w_t - \frac{\alpha}{\sqrt{G_t + \varepsilon}} m_t$

$m_t = \beta m_{t-1} + (1-\beta) g_t$


\subsection{Батчевая нормализация.}

\href{https://neerc.ifmo.ru/wiki/index.php?title=Batch-normalization}{Batchnorm}


\subsection{Сверточные сети: понятие свертки, паддинга, пулинга, страйда. Идея, архитектура
и алгоритм обучения.}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8}{Сверточные сети}

Паддинг = доп пиксели вокруг картинки.

Страйд = шаг свертки. Прикладываем образец через n пикселей.

Lol: Через MaxPooling слои градиент проходит только через те ячейки,
в которых возвращается значение (max), во всех остальных направлениях
градиент равен нулю.


\subsection{Задачи семантической сегментации и дедукции объектов. Примеры современных
решений.}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BD%D0%B0%D1%85%D0%BE%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2_%D0%BD%D0%B0_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B8}{Задача нахождения объектов}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%B5%D0%B3%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%86%D0%B8%D1%8F_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9}{Сегментация конкретно}


\subsection{Обработка последовательностей в машинном обучении. Рекуррентные сети:
идея, архитектура и алгоритм обучение.}

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%BA%D1%83%D1%80%D1%80%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8}{Рекуррентные нейронные сети}

$h_i = f(W_{hh} h_{i-1} + W_{hx}x_i + b_h)$

$\hat{y_i} = f_1(W_{yh} h_i + b_y)$

BPTT = разворачивает все повторяющиеся обращения к рекуррентной ячейке
во времени, как бы добавляя новые слои, затем протаскивает ошибку от
последнего слоя к первому.

Могут быть
\begin{itemize}
	\item seq2seq
	\item seq2one
	\item one2seq
\end{itemize}


\subsection{Глубокие сети с памятью: идея, архитектура и алгоритм обучение.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%94%D0%BE%D0%BB%D0%B3%D0%B0%D1%8F_%D0%BA%D1%80%D0%B0%D1%82%D0%BA%D0%BE%D1%81%D1%80%D0%BE%D1%87%D0%BD%D0%B0%D1%8F_%D0%BF%D0%B0%D0%BC%D1%8F%D1%82%D1%8C
}{LSTM}


\subsection{Классификация рекуррентных сетей. Двунаправленные рекуррентные сети и
глубокие рекуррентные сети: архитектура и алгоритм обучения.}

\subsubsection{Двунаправленные}

$h_t^f = \sigma^f(W_x^f x_t + W_h^f h_{t-1}^f + b^f)$

$h_t^b = \sigma^b(W_x^b x_t + W_h^b h_{t-1}^b + b^b)$

$\hat{y_t} = f_1 (W_y h_t + b^y)$

\href{https://neerc.ifmo.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%BA%D1%83%D1%80%D1%80%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8#.D0.94.D0.B2.D1.83.D0.BD.D0.B0.D0.BF.D1.80.D0.B0.D0.B2.D0.BB.D0.B5.D0.BD.D0.BD.D1.8B.D0.B5_.D1.80.D0.B5.D0.BA.D1.83.D1.80.D1.80.D0.B5.D0.BD.D1.82.D0.BD.D1.8B.D0.B5_.D1.81.D0.B5.D1.82.D0.B8}{
	Двунаправленные сети
}

\subsubsection{Глубокие рекуррентные сети}

Глубокие сети = сети с несколькими рекуррентными слоями.

\subsection{Механизм внимания в рекуррентных сетях: принцип, архитектура и алгоритм
обучение.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=Механизм_внимания
}{Механизм внимания}


\subsection{Векторные представления слов. Word2Vec,Fast-text, BERT.}
\label{sec:word_embeddings}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%92%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BD%D0%BE%D0%B5_%D0%BF%D1%80%D0%B5%D0%B4%D1%81%D1%82%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81%D0%BB%D0%BE%D0%B2
}{Векторные представления слов}

\D{
	Векторное представление слов (англ. word embedding) — общее название для различных подходов к моделированию языка и обучению представлений в обработке естественного языка, направленных на сопоставление словам из некоторого словаря векторов небольшой размерности. 
}


\subsection{Задача кластеризации. Меры оценки. Графовые алгоритмы. Иерархические
алгоритмы.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%9E%D1%86%D0%B5%D0%BD%D0%BA%D0%B0_%D0%BA%D0%B0%D1%87%D0%B5%D1%81%D1%82%D0%B2%D0%B0_%D0%B2_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B5_%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8
}{Оценка качества кластеризации}

$F = \frac{\sum [y_i = y_j] \rho(x_i, x_j)}{\sum [y_i = y_j]} \to \min$ - среднее внутрикластерное расстояние

$F = \frac{\sum [y_i \neq y_j] \rho(x_i, x_j)}{\sum [y_i \neq y_j]} \to \min$ - среднее внутрикластерное расстояние

\href{
	http://www.machinelearning.ru/wiki/images/archive/2/28/20150427184336%21Voron-ML-Clustering-slides.pdf
}{Графовые алгоритмы}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%98%D0%B5%D1%80%D0%B0%D1%80%D1%85%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F
}{Иерархическая кластеризация}


\subsection{Задача кластеризации. Меры оценки. Алгоритм k-Means. Плотностные
алгоритмы.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%9A%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F#.D0.9C.D0.B5.D1.82.D0.BE.D0.B4_K-.D1.81.D1.80.D0.B5.D0.B4.D0.BD.D0.B8.D1.85_.28.D0.90.D0.BB.D0.B3.D0.BE.D1.80.D0.B8.D1.82.D0.BC_.D0.9B.D0.BB.D0.BE.D0.B9.D0.B4.D0.B0.29
}{k-means + dbscan}



\subsection{Задача уменьшения размерности. Фильтрующие методы выбора признаков.}
\label{sec:dim_reduction}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%A3%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B5%D0%BD%D0%B8%D0%B5_%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D0%B8#.D0.A4.D0.B8.D0.BB.D1.8C.D1.82.D1.80.D1.8B
}{фильтры}


\subsection{Задача уменьшения размерности. Алгоритмы-обертки и встроенные методы.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%A3%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B5%D0%BD%D0%B8%D0%B5_%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D0%B8#.D0.9E.D0.B1.D0.B5.D1.80.D1.82.D0.BE.D1.87.D0.BD.D1.8B.D0.B5_.D0.BC.D0.B5.D1.82.D0.BE.D0.B4.D1.8B
}{Обертки и встроенные методы}


\subsection{Задача уменьшения размерности. Алгоритмы PCA, tSNE и UMAP.}

\subsubsection{PCA}

Хотим уменьшить размерность так, чтобы изначальные признаки восстанавливались
линейным преобразованием с минимальными искажениями $||F - GU^T|| \to \min$

Берем m максимальных собственных значений $F^T F$ и из соответствующих им
векторов строим матрицу $U$ (вектора - столбцы).

Можно заюзать SVD.

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D0%BB%D0%B0%D0%B2%D0%BD%D1%8B%D1%85_%D0%BA%D0%BE%D0%BC%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%82_(PCA)
}{PCA}

\subsubsection{t-SNE}
\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D1%82%D0%BE%D1%85%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%B2%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81%D0%BE%D1%81%D0%B5%D0%B4%D0%B5%D0%B9_%D1%81_t-%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5%D0%BC
}{t-SNE}

\subsubsection{UMAP}
\href{
	https://ru.wikipedia.org/wiki/UMAP
}{UMAP}


\subsection{Задача уменьшения размерности. Автоэнкодеры.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%B2%D1%82%D0%BE%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA
}{Автоэнкодеры}


\subsection{Алгоритм Expectation maximization.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=EM-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC
}{EM-алгоритм}


\subsection{Задача и алгоритмы частичного обучения.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81_%D1%87%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%BD%D1%8B%D0%BC_%D0%BF%D1%80%D0%B8%D0%B2%D0%BB%D0%B5%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%D0%BC_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8F
}{Semi-supervised learning}


\subsection{Задача и алгоритмы активного обучения.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5
}{Active learning}


\subsection{Задача и алгоритмы сэмплирования.}

\href{
	http://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B_%D1%81%D1%8D%D0%BC%D0%BF%D0%BB%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F&mobileaction=toggle_view_desktop
}{Sampling}


\subsection{Задача и алгоритмы обучения “с первого взгляда”.}


\subsection{Задача и алгоритмы поиска аномалий и удаления шумов.}

\href{
	https://dyakonov.org/2017/04/19/%D0%BF%D0%BE%D0%B8%D1%81%D0%BA-%D0%B0%D0%BD%D0%BE%D0%BC%D0%B0%D0%BB%D0%B8%D0%B9-anomaly-detection/
}{Помойка про поиск аномалий}


\subsection{Задача генерации объектов. PixelCNN и PixelRNN: идея, архитектура и
алгоритм обучение. Вариационные автокодировщики.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D1%8F_%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2
}{Генерация объектов}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=PixelRNN_%D0%B8_PixelCNN
}{PixelCNN and PixelRNN}

\href{
	http://neerc.ifmo.ru/wiki/index.php?title=%D0%92%D0%B0%D1%80%D0%B8%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B0%D0%B2%D1%82%D0%BE%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA
}{Вариационные автокодировщики}


\subsection{Генеративные противоборствующие сети: идея, архитектура и алгоритм
обучения. СGAN и DCGAN: идея, архитектура и алгоритм обучения.}

\href{
	https://neerc.ifmo.ru/wiki/index.php?title=Generative_Adversarial_Nets_(GAN)
}{GANs}

\end{document}
